<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>N4A Space</title>
  
  <subtitle>To understand and be understood</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://n4a.github.io/"/>
  <updated>2019-12-27T09:42:57.780Z</updated>
  <id>https://n4a.github.io/</id>
  
  <author>
    <name>N4A</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>哈佛大学校长350周年校庆讲话（1636-1986）</title>
    <link href="https://n4a.github.io/2019/12/27/%E5%93%88%E4%BD%9B%E5%A4%A7%E5%AD%A6%E6%A0%A1%E9%95%BF350%E5%91%A8%E5%B9%B4%E6%A0%A1%E5%BA%86%E8%AE%B2%E8%AF%9D%EF%BC%881636-1986%EF%BC%89/"/>
    <id>https://n4a.github.io/2019/12/27/哈佛大学校长350周年校庆讲话（1636-1986）/</id>
    <published>2019-12-27T06:20:43.000Z</published>
    <updated>2019-12-27T09:42:57.780Z</updated>
    
    <content type="html"><![CDATA[<p>​        从我们上次聚会庆祝哈佛大学校庆300周年纪念日起，50年过去了。人们从这段历史中可以清楚得看出，在今后的几十年内，几乎不大可能有什么大的动荡会改变哈佛，美国和整个地球。美国在世界上演的角色也没多大可能发生变化。少数民族和妇女对于更多机会的要求，医疗保健的巨大变化，技术的急速发展都不会吞没美国。最重要的危险，仍然是对知识的极端重要性的估计不足。</p><a id="more"></a><p>　　在所有因素中，正是知识改变了哈佛和其他大学的面貌。从上次世界大战开始，并在战后继续发展的电子学和生物工艺学的进步，各行各业的精通业务，政策分析运用和现代医学的革命；使我们更加清楚地认识到，知识，专门知识和新的发明是社会进步的关键因素。</p><p>　　由于大学是知识发展的主要源泉，大学比50年前我们的前人所想象的更为重要。幸而，美国的大学以及大的热情和创造力迎接了这一挑战，有力的环境帮助我们取得了成功。第二次世界大战摧毁了许多国家的高等教育，而美国的大学不但幸免于难，而且还由于一批杰出的科学家和学者为了逃避欧洲的政治迫害而跑到美国而得到了加强，美国的大学还得到了世界上最繁荣的经济的支持。但最重要的是，我们有了一套组织高等学校的特殊方法。</p><p>　　在我们国家的历史上，大学一直有着不平凡的自由，政府官员很少干预州立学校的事务，私人集团也可以建立它们自己的学校。所有学校都在为得到优秀的学生，教师和设备进行激烈而又友好的竞争。我们对这一体制已经如此熟悉，从而认为这都是理所当然的。其实，这是世界上独一无二的，在几乎所有其他国家内，大学严重地依赖政府，并在中央计划下运行。</p><p>　　我们这种自由而又分散的体制有着伟大的力量，它允许各自为政的独立学术中心存在，提高了创造力和适应力。由于避免了政府的控制，决策权利就掌握在有识之士的手中，鼓励竞争成了努力进取以超越他人的动力。我们在取得科学研究成果，进行高质量的职业培训，为社会不同阶层服务，为广大的个性各异的学生提供不同课程等方面形成了一个被广泛认为是世界上最好的大学网络。</p><p>　　因此，有理由认为现在是庆祝美国这所最古老的大学的诞辰的最好时刻，也是庆祝美国教育取得最伟大成就的最好时刻。但我们学校当初是清教徒建立的，如果说350年来哈佛有一个贯穿始终的特点的话，那就是我们总在心神不定的担忧，即使在从外界形势看来没有任何理由这样时也是如此。当我们为取得的成就而高兴时，会突然感到一种异样的阵痛，虽然我们强忍着，但也不免说出来。我们知道有多少学院是在全盛时刻种下了日后衰退的种子。我们的第二天性使我们从自我陶醉中清醒过来，时时问一下自己有什么敌对的力量存在。命运会有什么改变，有什么内部矛盾和过分行为会消弱我们的大学或阻止它满足现代社会和人类的需要而作出贡献。</p><p>　　为了寻找我们忧虑的根源，我们最好从观察学校的外部环境着手。学校的成功和繁荣吸引了人们的注意，但这种注意并不总是令人欢迎的。当学校的影响和重要性日益增加，声望和财产日益增长时，各种集团自然会受到诱惑，希望利用学校来达到自己的目的。最近几年我们在这方面有许多证据，军事和情报部门试图使我们的教授们参加秘密的研究工作，并对我们作出种种限制，以避免我们的科学发明落入敌人之手。商人们寻求和我们的科学家建立关系，以帮助他们开发新产品。社会活动家敦促学校利用自己的资本，购买力，尊严和威望同种族隔离等罪恶和不公正作斗争。公众指望我们利用我们的财富和影响力来帮助解决地方问题。</p><p>　　在回答这些问题的时候，必须十分明确：<em>大学的职责是为养育自己的社会服务，问题是如何才能为社会作出最大贡献，以及所需的条件到底是什么。</em>校外的集团时常错误地认为，既然大学成功地进行了教学和研究工作，那么他一定可以操纵政治机构，或者解决社会问题。他们时常迫使大学冒牺牲自己独立性的危险而参与政治斗争，或者要求他们做一些有损学术公开和自由的事情，而公开和自由正是一个健康研究环境必不可少的特性。在这种情况下，问题已不在于人们寻求大学的帮助以解决社会问题，而在于人们要求大学的所作的与大学的性质相矛盾，从而对大学的基本功能够成了威胁。</p><p>　　来自大学外部的另一个令人忧虑的变化是，政府的规定有越来越多的势头。当知识和高等教育在社会中扮演的角色越来越活跃的时候，国家自然希望能确保大学为公共利益提供服务。大学已经被规定禁止种族歧视，推进正当活动，保证对研究基金的使用进行说明，保证残废人的入学权利，控制学生的入学分数，等等。</p><p>　　所有这些规定都是出于好的动机，大多数是完全合理的，问题在于政府的干预还要走多远。里根年代使我们暂时免于更多规定的束缚，但诱使未来政府做出新的规定的可能性依旧大量存在。例如，当权者计划使毕业生的数量与国家的需要协调一致；对学校的发展计划和新设施的建立进行审核以避免重复和浪费；制定详细的规则来检查大学的体育比赛；制定防止学生得到不公正分数和入学遭到招生办公室不合理拒绝的保护性条款；等等。</p><p>　　在考虑这些规定时，我们应该清醒地认识到，大学必须是对公众负责的，不断增加的规则正在威胁使我们大学在为公众服务方面取得成功的那些因素。美国的高等教育是在特色各异，地方自治和竞争中繁荣起来的。而我们的规定就意味着千篇一律，中央计划和官僚控制。我们头上的规定越多，把我们周围只是很好的环境变为严重阻碍国外兄弟院校的那种制度的危险就越大。</p><p>　　规定越来越多的前景是与大量令人烦扰的问题相关联的。许多人对于研究性大学的影响和威望不断提高的心情是矛盾的。你们毫无疑问已经在最近的报纸和杂志上看到关于你们母校的一些报道。照片很漂亮，文章的调子是友好的和建设性的。然而读一下内容，你将会发现他们都在强调哈佛的成就–在社会上的影响，基金的数量，在高级职位的毕业生的数量。我猜想我们中间的大多数人都在暗自庆幸自己能与这样一个受到尊敬的学校联系在一起。但我们不应该忘记他们描绘的，只是一幅对哈佛和其他大学真正贡献歪曲的图画。</p><p>　　我们都能够了解哈佛成就的本来面目。除去偶尔的科学突破外，人们从那些大量的书籍和无数增长知识的学生中间辛勤劳动的学者身上看不到许多戏剧性的东西。用想象代替这种现实并不是完全无害的。当人们读到有关哈佛文凭的金钱价值，哈佛基金的不断膨胀，老校友网的无形影响的报道时，羡慕和尊敬很容易变成嫉妒和仇恨。</p><p>　　这种看法虽然不是什么新的东西，但国家现在资助科学发明和学生助学金方面起的作用如此重要，已使危险性危险增大。认识到教育和研究工作的重要性，联邦和州政府官员对大学是很慷慨的，这使得学校的活动更多地依靠学校所不能控制的力量。哈佛和其他有类似情况的大学处于一种50年前的前任无法想象的危险境地，我们的繁荣越来越依赖于社会各方面对我们的态度。正如我们从近几年来几个事件中了解到的，对研究性大学的优越和骄傲的不满情绪很容易导致立法和行政机构的敌对活动。</p><p>　　虽然我们校门外的危险已经足够大的了，但很可能更大的危险来自我们学校内部的紧张局势。洛思尔校长在1936年曾就这一危险性评论说：”<em>如果我们对历史没有搞错的话，一个学校在其富有活力的时候是很少会毁灭的，而缺乏活力的学校则是自寻死亡，这时魔鬼就会乘虚而入，从而将其至于死地。</em>”我们应该牢记这个警告，密切注意那些妨碍我们履行职责的内部矛盾和压力。</p><p>　　一般人在列举学校成功的弱点时，首先强调骄傲的危险性是很时髦的。然而，在所有我们所关心的问题内，骄傲这个问题对我们来说是处于最后一位的。我在哈佛的这些年内，从没有看见一个学校像我们现在这样关心走下坡路的危险，从没有这么多人决心进行创造性的工作。如果我们要寻找问题，则确有一些问题是需要我们注意的。</p><p>　　一个问题是大学在确定重大项目和限制发展上遇到的困难。这种困难是可以理解的。知识和专门知识越来越重要，其用途也成倍增长，富有魅力的机会不断出现。由于大学在其性质上是无政府的，并由于授予教授自由权而昌盛，因而新科学不断出现，旧的科目仍然保存着，学校的扩大因此不可阻挡。</p><p>　　随着这个进程的不断继续，大学变得更难于管理。有如此之多研究项目需要关心，如此之多的必须会面，如此之多的地方会出现问题，如此之多的活动要求经费；解决这些问题足以耗费最有才能的管理者的聪明才智。而有经验的管理者必须准确知道什么是大学所绝对不能做的。由学校的性质决定，大多数官员都是从教员中挑选出来的，由于缺乏管理艺术的训练，这些学术领导人很容易被行政事务所吞没，而几乎没有时间考虑如何改进教育和为开拓性研究创造机会。因此我们可能陷入一种可悲的境地，根据他们的学术经历而任命他们，但他们却没有时间来思考学术问题。校长为此感到苦恼已经很长时间了，现在已轮到学院院长，系主任和重要项目的负责人了。</p><p>　　在座的很多听众很快就会意识到，大学的不断扩大需要不遗余力地寻求基金。在高等教育竞争越来越激烈的今天，学校代表必须更加机敏地从政府和个人手中得到资金。这种压力充其量只能造就一些能应付各种烦恼的好脾气的管理者。在第一流的运动竞赛中，这种压力经常变为对运动员进行丢人的管制。在科学方面，财政压力迫使学校进入工业公司或政府计划安排的项目，其中一些需要保密或附有其他限制，这将危及自由，公开的研究环境。在我们这些在学术中辛勤耕耘的劳动者看来，我们高尚的目的使我们使用的这些方法合理化了。劳伦斯主教在为哈佛集资的时曾经说过：”<em>当你在做一个真正伟大的事业时，你就不能不顾虑重重。</em>”而在那些不具备这位主教的热情的校外人士看来，这种狂热的追求基金会更加证明他们的观点，即学校只不过是另一个为自己追求特殊利益的合法组织而已。</p><p>　　教师在发展自己的系和保持自己的研究中心而奋斗时，也越来越深地卷入了筹集资金和行政事务的苦役。但对很多教授来说，更加束缚他们的是由于社会对专业知识的急需而出现在他们面前的各种机会:提供政府咨询，为政府服务，为大会做报告，为感兴趣的公众介绍某一个知识领域，等等。这些机会对于专业学院和文理学院的教师都大量存在的。逐渐地，不知不觉地，这些校外活动成了许多教授寻求刺激和变化，提高地位和金钱收入的最大来源。</p><p>　　这些活动并不是完全有害的。教授们与他们感兴趣的人和事相接触可以解决一些有价值的实际问题，否则他们可能只知道纸上谈兵，但这些活动终究占去了为实现学校更为主要的目的而必须花费的时间。</p><p>　　在未来50年内，以上所述的压力和诱惑都不会有所减轻。相反，随着知识总量的不断增加，学者们将发现更难集中精力于他们的研究领域。社会将不断需要新的专门知识，校外机会将有所增加。大学为了保证自己的研究项目和活动，将更加需要教师门对学校管理的支持。</p><p>　　对教师的要求增加了，我们将如何回答呢？我不知道，对此也的确有理由感到忧虑。在一个学者的只是如此专门化，又如此依靠外界的承认和支持的现实世界里，他们同时忠诚于大学，职业和提供他们基金的势力。当这些相互抵触的压力增加时，教员们将更加难于摆脱周围社会的影响。难道我们能希望教授们不受这个时代流行的价值观念的影响么？这一代的学者是随着水门事件和越南战争而成长起来的，他们对现存制度有着普遍的不信任。我们不应指望他们有着他们的前辈和其他行业中存在的忠诚。相反，在这个鼓励成功和生活多样化的世界的影响下，我们很容易发现，越来越多的教授将试图把自由，安全的学术工作同风险较多，性质较为低下却有较多金钱和较高知名度的工作结合起来。</p><p>　　不管这种预测是否现实，有一件事情是确定无疑。金钱虽然十分重要，但影响学校的关键因素是时间。</p><p>　　时间的效用是不能明显看出来的。例如，我们通过细心的观察会发现，把每一分钟都用于学习的学生常常成绩不能提高，反而会下降。对于学者来说也是如此，参加很多有兴趣的活动能够使他们改进工作的质量。但我们也同样清楚，一旦校外活动的负担达到某一个极限点，校内工作就会受到严重影响，几年内，这种可能性将成为现实，越来越多的教员将超越这一局限。</p><p>　　如果以上情况发生，会产生什么样的结果？其影响可能不会很快显示出来。学术成果的数量可能不会受到多大影响，讲座仍然是有竞争和有内容的。但由于不被打扰的学术研究时间越来越少，学术成果将越来越缺乏深度和广度，并且将过多得依靠助手的工作。教师和学生的课外接触时间也将减少，这些接触虽然看起来是可有可无的，但却可能为青年学生在大学中的生活留下最值得记忆和最关键的一刻。教师也将有时间去认真了解如何才能帮助学生改进他们的学习。我们已经不能充分地了解大学教纲的完成情况，更不用说进行足够系统的工作去改进了。我们对学生入学时的聪明过人谈得很多，对他们入校后进步了多少却知之甚少。无怪乎外界总是用粗俗的用词来形容大学教育而忽略其真正的意义。</p><p>　　现在，你们已经对我们的成功所带来的大量问题听得很多了。这些问题与过去50年大学所克服的那些挑战大不相同。我们已经无法依赖我们高等教育体制本身的力量来使我们沿着正确的方向前进，因为我所描述的那些危险正是这个制度的产物。展望未来，我们必须竭尽全力来抵抗那些迫使我们偏离正确轨道的压力。</p><p>　　为了完成这个任务，我们必须把一件事情牢记在心：我所描述的危险都有一个共同特点，它们都是由于对大学本来的目的和达到这些目的所需要的基本条件认识错误而造成的，而这些都是很容易被忽视的。由于我们已经习惯于从研究性大学考虑问题，因此我们之中的许多人都认为这些都是理所当然的，一些人则为了大到一些看起来更为紧迫的目的而将大学的基本目的置之一旁。在很多时刻，新的环境已经在很大程度上威胁我们的基本价值了，而我们却一无所知。无论是什么原因，我们必须非常清楚大学一直完成的很好的职责和履行这些职责所需的条件。</p><p>　　尤其是，我们需要说服公众并时时提醒我们自己大学不是营业性公司，不是国家安全的工具，不是急于在世界上强行推行自己社会观点的军事机关。许多组织可以提供咨询或帮助解决社会问题，或开发新的产品，或推行新的军事目的，但只有大学或类似的学术机构能够发现为提出创造性解决办法作基础的知识，只有大学能够教育出永远作出判断性决策的人。许多人可以成为企业家，律师或者有影响的顾问，但是只有具有安全和自由保证的学者才能去探求科学真理。阅历可以锻炼我们的判断力，使我们更加成熟，但只有教育能同时发展智能，启发新的兴趣，树立志向，提出重要问题，加强理解力的多重目的。只有这些，才是大学给以学生的真正贡献，而不是闪闪发光的大学牌子，或其毕业生在社会上的影响。</p><p>　　为了说明基本目的崇高价值，让我引用洛厄尔校长另一段话来结束我的演讲。虽然洛厄尔对于哈佛的将来所面临的重大事件和变化并不比我们今天知道的更多，但他确实知道哈佛真正的生命之源是什么。他说：”<em>学生们一代接着一代，如同海浪一浪接着一浪冲向陆地。有时候是静止着，有时候则带着暴风雨的怒吼。不论我们认为人的历史是单调的或是狂暴的，有两个事物总是新的，这就是青春和对知识的追求，这也正是一个大学所关心的。我们学校的年龄已经可以用世纪来计算，但只要她热切的追求这两件事物，她就永远不会衰老。随着时代的变迁，为达到目的使用的方法可能改变，但目的本身是永远不变的。</em>”</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​        从我们上次聚会庆祝哈佛大学校庆300周年纪念日起，50年过去了。人们从这段历史中可以清楚得看出，在今后的几十年内，几乎不大可能有什么大的动荡会改变哈佛，美国和整个地球。美国在世界上演的角色也没多大可能发生变化。少数民族和妇女对于更多机会的要求，医疗保健的巨大变化，技术的急速发展都不会吞没美国。最重要的危险，仍然是对知识的极端重要性的估计不足。&lt;/p&gt;
    
    </summary>
    
    
      <category term="生命" scheme="https://n4a.github.io/tags/%E7%94%9F%E5%91%BD/"/>
    
      <category term="知识" scheme="https://n4a.github.io/tags/%E7%9F%A5%E8%AF%86/"/>
    
      <category term="大学" scheme="https://n4a.github.io/tags/%E5%A4%A7%E5%AD%A6/"/>
    
      <category term="教育" scheme="https://n4a.github.io/tags/%E6%95%99%E8%82%B2/"/>
    
  </entry>
  
  <entry>
    <title>Pandas practice</title>
    <link href="https://n4a.github.io/2019/12/09/Pandas-practice/"/>
    <id>https://n4a.github.io/2019/12/09/Pandas-practice/</id>
    <published>2019-12-09T08:26:35.000Z</published>
    <updated>2019-12-09T08:29:39.884Z</updated>
    
    <content type="html"><![CDATA[<p>Pandas basics practice.</p><a id="more"></a><iframe src="/html/learn_pandas.html" width="800" height="1000"> Your browser does not support iframe</iframe>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pandas basics practice.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Pandas" scheme="https://n4a.github.io/tags/Pandas/"/>
    
      <category term="Numpy" scheme="https://n4a.github.io/tags/Numpy/"/>
    
      <category term="Python" scheme="https://n4a.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Session Recommendation</title>
    <link href="https://n4a.github.io/2019/09/25/Session-Recommendation/"/>
    <id>https://n4a.github.io/2019/09/25/Session-Recommendation/</id>
    <published>2019-09-25T08:47:45.000Z</published>
    <updated>2019-12-09T08:44:49.247Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Attention-Mechanism-in-Session-Recommendation"><a href="#Attention-Mechanism-in-Session-Recommendation" class="headerlink" title="Attention Mechanism in Session Recommendation"></a>Attention Mechanism in Session Recommendation</h2><p>This report focuses on the attention mechanism used in some previous session recommendation works. The conclusion is summarized in the final part: <a href="#Some Intuition of Using Candidate Item as Query">Some Intuition of Using Candidate Item as Query</a></p><a id="more"></a><h2 id="Neural-Attentive-Session-based-Recommendation"><a href="#Neural-Attentive-Session-based-Recommendation" class="headerlink" title="Neural Attentive Session-based Recommendation"></a>Neural Attentive Session-based Recommendation</h2><p>CIKM’17, Best Paper Runner-ups Award</p><p>Problem: Session recommendation.</p><p>Gap: Previous works only consider the user’s sequential behavior in the current session, whereas the user’s main purpose in the current session is not emphasized.  An example is shown in the following figure. For the session in the left part, the global recommender models the user’s whole sequential behavior to make recommendations while the proposed local recommender could capture the user’s main purpose to make recommendations.</p><p><img src="/img/srs/purpose_intuition.PNG" alt=""></p><p>Method:</p><p><img src="/img/srs/purpose_arch.PNG" alt=""></p><p>As shown in the above figure, the  process is summarized as</p><ol><li>In the upper left part, a GRU based encoder is used to encode the session of a user. The output state is denoted as $h_t^g$.</li><li>In the lower left part, another GRU is used to encode the session of the user. The outputs are a sequence of hidden states, denoted as ${h_1^l, h_2^l, …,h_t^l}$.</li><li>In the middle, the attention mechanism is utilized to generate the preference of the current user. The attention point or query key is $h_t^g$ and the memory pool is ${h_1^l, h_2^l, …,h_t^l}$.</li><li>In the right part, the score for each candidate item $i$ is calculated as $S_i = emb_i^TBc_t$ where $B$ is parameter. And then a Softmax Layer is used to normalize each score.</li></ol><p>Provide a benchmark:</p><p><img src="/img/srs/purpose_benchmark_dataset.PNG" alt=""></p><p><img src="/img/srs/purpose_benchmark_exp.PNG" alt=""></p><p>Notes: The authors emphasize that in traditional methods, the main purpose of a session was outlooked. And then the authors utilize attention mechanisms to solve this problem. However, at present, using $h_t^g$ as a query is not reasonable enough for three reasons as follows:</p><ol><li>$h_t^g$ is generated by capture information of the global sequence. So $h_t^g$ is similar to every item in the session, Using it to estimate attention weight tends to still capture the overall info of the sequence.</li><li>Based on RNN mechanism, $h_t^g$ tends to focus more on the last item. If the last item is not similar as the target item, using $h_t^g$ as query will generate the wrong signal.</li><li>Based on RNN mechanism, $h_t^g$ tends to focus more on a category of items that are frequently interacted at the sequence. When the user wants to select an item from a lot of categories of items, then $h_t^g$ is about evenly influenced by every category of items and thus still can not capture the main purpose as well as enough.</li></ol><p>A possible way to avoid these problems is to use the embedding of the candidate item $i$ as the query to extract the most related preference, denoted as $c_t^i$, of the user for the candidate item. And then the predicted score for each candidate item is calculated as $S_i = emb_i^TBc_t^i$</p><h2 id="Other-works-that-follow-the-work"><a href="#Other-works-that-follow-the-work" class="headerlink" title="Other works that follow the work"></a>Other works that follow the work</h2><h3 id="Short-Term-Atention-Memory-Priority-Model-for-Session-based-Recommendation"><a href="#Short-Term-Atention-Memory-Priority-Model-for-Session-based-Recommendation" class="headerlink" title="Short-Term Atention/Memory Priority Model for Session-based Recommendation"></a>Short-Term Atention/Memory Priority Model for Session-based Recommendation</h3><p>KDD’18</p><p>Gap: Capture both long-term and short-term interests in a session</p><p>Method: </p><p><img src="/img/srs/stamp.PNG" alt=""></p><p>As shown in the above figure, given the embeddings ${x_1, x_2,…,x_t}$ of a session, the process is summarized as follows:</p><ol><li><p>$m_s$ is the average of all embeddings, and then the long-term interests is got by an Attention Net in which the queries are $m_s$ and $x_t$. Then $m_a$ is transformed to $h_s$ by a MLP layer</p></li><li><p>short-term interest $m_t = x_t$ and then is transformed to $h_t$ by another MLP layer.</p></li><li><p>the score for a candidate item $x_i$ is calculated by a by a trilinear product of three vector defined as:<br>$$<br>&lt;a, b, c&gt; = \sum_{i=1}^da_ib_ic_i<br>$$</p></li></ol><p>Notes:</p><ol><li>the model does not use the RNN layer to handle embeddings but directly applies the Attention Network. This may suggest that RNN layer is not important in this work.</li><li>Also the last embedding is used as query</li></ol><h3 id="Session-based-Recommendation-with-Graph-Neural-Networks"><a href="#Session-based-Recommendation-with-Graph-Neural-Networks" class="headerlink" title="Session-based Recommendation with Graph Neural Networks"></a>Session-based Recommendation with Graph Neural Networks</h3><p>AAAI’19 </p><p>Problem: Session Recommendation</p><p>Gap: Transitions among distant items are often overlooked by previous methods. </p><p>Method: Use Graph to model item relation in sessions and utilize Graph Neural Networks to capturing transitions of items and generate accurate item embedding vectors. For example, as follows, the three sessions are constructed as a graph.</p><p><img src="/img/aaai19/session-graph.PNG" alt="Session graph"></p><p>Notes: </p><ol><li>In Attention Network, the authors also use the embedding of the last interacted item in the session as the query.</li><li>The model also abandoned RNN layer. </li></ol><h3 id="A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation"><a href="#A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation" class="headerlink" title="A Repeat Aware Neural Recommendation Machine for Session-based Recommendation"></a>A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</h3><p>AAAI’19 </p><p>Problem: session recommendation</p><p>Gap: propose a novel <em>repeat consumption</em> phenomenon where the same item is re-consumed repeatedly over time. The following table shows the repeat ratio in three public datasets.  However, no previous works have emphasized <em>repeat consumption</em> with neural networks. (Multi-armed bandit problem has been studied for a long time to solve the repeat-explore dilemma for general recommendations.)</p><p><img src="/img/aaai19/repeat-ratio.PNG" alt=""></p><p>Method: </p><p><img src="/img/aaai19/repeatnet.PNG" alt=""></p><p>As shown in the above figure, the process is summarized as:</p><ol><li>Use GRU to encode the session sequence of a user.</li><li>Use attention mechanism to merge all hidden states with the last hidden state as the query. Then use a dense network to transform the merged vector into a two-dimension vector with the first value as the probability of <em>repeat</em> and the other as the probability of <em>explore</em></li><li>For repeat mode, decode the hidden states to calculate the score for each item (new items get 0 points)</li><li>For explore mode, decode the hidden states with attention to calculate for each item (old items get 0 points)</li><li>Use the score and whether the item is new as supervising info to train the model with a negative log-likelihood loss and a logistic loss.</li></ol><p>Notes: In Explore Mode, the Attentive Encoder uses same attention mechanism that uses the last hidden state $h_t$ as the query.</p><h2 id="Attention-with-Candidate-Item"><a href="#Attention-with-Candidate-Item" class="headerlink" title="Attention with Candidate Item"></a>Attention with Candidate Item</h2><p>The idea of using the candidate item as the query has been utilized in some previous works. Here are some works.</p><h3 id="Neural-Attentive-Item-Similarity-Model-for-Recommendation"><a href="#Neural-Attentive-Item-Similarity-Model-for-Recommendation" class="headerlink" title="Neural Attentive Item Similarity Model for Recommendation"></a>Neural Attentive Item Similarity Model for Recommendation</h3><p>IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING </p><p>Problem: CF-based recommendation</p><p>Gap: Traditional MF based methods need to retrain for real-time recommendations to update users’ preference vectors. On the other hand, item-to-item CF could make real-time recommendations much easier to achieve. However, previous works ignore different item has a different influence on the recommendation to users. So the authors use attention mechanisms to calculate the weight of influence for each item in one’s historical interactions.</p><p>Method:</p><p><img src="/img/srs/nais-arch.PNG" alt=""></p><p>As shown in the above figure, the process is summarized as follows:</p><ol><li>Each item has two embeddings: the embedding, denoted as $q$, when the item is in one user’s interaction and the embedding, denoted as $p$, when the item is a candidate item.</li><li>The score $s_{ij}$ is the similarity between the item $i$ in the user’s interactions and the candidate item $j$</li><li>The final score is the weighted sum of all ${s_{ij}}$</li><li>The weight $a_{ij}$ is estimated by attention mechanism with the candidate item as the query.</li></ol><p>Notes: The model ignores the time order of each interacted item. Besides, each item in one’s interactions is independent and thus the context info is neglected.</p><h2 id="Non-attention-works"><a href="#Non-attention-works" class="headerlink" title="Non-attention works"></a>Non-attention works</h2><h3 id="Improved-Recurrent-Neural-Networks-for-Session-based-Recommendations"><a href="#Improved-Recurrent-Neural-Networks-for-Session-based-Recommendations" class="headerlink" title="Improved Recurrent Neural Networks for Session-based Recommendations"></a>Improved Recurrent Neural Networks for Session-based Recommendations</h3><p>Deep learning workshop on RecSys’16</p><p>experiments skills, adapt various techniques from the literature for this task.</p><ol><li>Data augmentation via sequence preprocessing and embedding dropout to enhance training and reduce overfitting</li><li>Model pre-training to account for temporal shifts in the data distribution</li><li>Distillation using privileged information to learn from small datasets.</li></ol><h2 id="Some-Intuition-of-Using-Candidate-Item-as-Query"><a href="#Some-Intuition-of-Using-Candidate-Item-as-Query" class="headerlink" title="Some Intuition of Using Candidate Item as Query"></a>Some Intuition of Using Candidate Item as Query</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>From the view of method, we argue that using the last hidden state as the query has the following drawbacks:</p><ol><li>$h_t^g$ is generated by capture information of the global sequence. So $h_t^g$ is similar to every item in the session, Using it to estimate attention weight tends to still capture the overall info of the sequence.</li><li>Based on RNN mechanism, $h_t^g$ tends to focus more on the last item. If the last item is not similar as the target item, using $h_t^g$ as the query will generate the wrong signal.</li><li>Based on RNN mechanism, $h_t^g$ tends to focus more on a category of items that are frequently interacted at the sequence. When the user wants to select an item from a lot of categories of items, then $h_t^g$ is about evenly influenced by every category of items and thus still can not capture the main purpose as well as enough.</li></ol><p>For the second drawback, the intuition is obvious. The last interacted item will be not consistent with the next item when the user’s interests drift. Here, we don’t use interest drift to explain this phenomenon. The interests drift is not proper for the phenomenon. We can combine this problem with the first and third drawbacks to define the problem as <strong>multi-interests problem</strong>: <em>Each user have many kinds of interests.</em></p><p>For example:</p><p><img src="/img/srs/multi-interests.PNG" alt=""></p><p>As shown in the above figure, from the interaction sequence, we can see the use likes three kinds of movies: Action, Romantic and Education. For the user, the choice of the next movie is mainly dependent on which kind of movie is published or recommended. In this scenario, we can recommend Education, Action or Romantic movies. It’s not proper for the user just like Education movies at present.</p><p>To model the interests of users at each time and capture users’ multi-interests at recommendation time, we propose to use RNN to model users’ dynamic interests and the attention mechanism with candidate item as the query to capture the multi-interests.</p><p>For the example above, if the candidate item is an Education movie, we will focus more on the forth and the last movies to give the evaluate the score. And the recommendation for Action movies or Romantic movies is similar. Besides, other kinds of movies will get lower attention from all interactions. In this scenario, if we use the last hidden state as the query, then just Education movies will get more attention. Romantic and Action movies may be regarded as noises.</p><h3 id="Support-of-Multi-interests"><a href="#Support-of-Multi-interests" class="headerlink" title="Support of Multi-interests."></a>Support of Multi-interests.</h3><p>An analysis of course recommendation datasets. (see <em>Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</em> for detail)</p><p>For previous attention-based works, when a user has interests in many different courses, the attention mechanism will perform poorly as the effects of the contributing courses are diluted by diverse historical courses.  An example is shown in the following figure, for a trained attention-based model, the real target course gets lower recommendation probability than a randomly selected course although it gives more related courses more weights.</p><p><img src="/img/aaai19/course-intuition.PNG" alt=""></p><p>More analyses on the dataset are shown in the following figure. From figure (b), we can the category ratio is evenly distributed for all users. From figure (c), we can see as the category ratio grows larger which means these users like more kinds of courses, a trained attention-based model give lower recommendation probability to the target courses.</p><p><img src="/img/aaai19/course-data.PNG" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Attention-Mechanism-in-Session-Recommendation&quot;&gt;&lt;a href=&quot;#Attention-Mechanism-in-Session-Recommendation&quot; class=&quot;headerlink&quot; title=&quot;Attention Mechanism in Session Recommendation&quot;&gt;&lt;/a&gt;Attention Mechanism in Session Recommendation&lt;/h2&gt;&lt;p&gt;This report focuses on the attention mechanism used in some previous session recommendation works. The conclusion is summarized in the final part: &lt;a href=&quot;#Some Intuition of Using Candidate Item as Query&quot;&gt;Some Intuition of Using Candidate Item as Query&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="session recommendation" scheme="https://n4a.github.io/tags/session-recommendation/"/>
    
      <category term="Attention" scheme="https://n4a.github.io/tags/Attention/"/>
    
  </entry>
  
  <entry>
    <title>Paper_Notes_About_Recommendation_in_AAAI19</title>
    <link href="https://n4a.github.io/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/"/>
    <id>https://n4a.github.io/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/</id>
    <published>2019-09-10T07:53:58.000Z</published>
    <updated>2019-09-24T08:10:25.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p><img src="/img/aaai19/overview.PNG" alt=""></p><a id="more"></a><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Explainability"><a href="#Explainability" class="headerlink" title="Explainability"></a>Explainability</h2><p>Recently, the recommendation community has reached a consensus that accuracy can only be used to partially evaluate a system. Explainability of the model, which is the ability to provide explanations for why an item is recommended, is considered equally important.</p><p>Papers like follows:</p><ol><li><a href="#explainable-reasoning-over-knowledge-graphs-for-recommendation">Explainable Reasoning over Knowledge Graphs for Recommendation</a>: Use knowledge graph(KG) info for explainability. Select the most related path in KG as the explanation.</li><li><a href="#Explainable Recommendation Through Attentive Multi-View Learning">Explainable Recommendation Through Attentive Multi-View Learning</a>: Construct a hierarchical (explicit) feature (e.g. meat, seafood and so on) tree for explainability. Select the most related features as explanation.</li><li><a href="#Dynamic Explainable Recommendation based on Neural Attentive Models">Dynamic Explainable Recommendation based on Neural Attentive Models</a>: Generate dynamic explanations at different time for a user by using GRU. An explanation is the most related sentence in the review of the recommended item.</li></ol><h2 id="Sequential-Recommendation"><a href="#Sequential-Recommendation" class="headerlink" title="Sequential Recommendation"></a>Sequential Recommendation</h2><p>Different from traditional MF that treats users and items equally, the methods model the interactions between users and items as a number of historical interaction sequences of users.  Then focusing on the sequential interactions of users, some methods was proposed to analysis the phenomenon like long-term interests, drifted interests, repeat consumption and some other task-specific aspects. The tasks include next item (basket) prediction (like POI), session recommendation. </p><ol><li><a href="#A Repeat Aware Neural Recommendation Machine for Session-based Recommendation">A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</a>: Emphasize the importance of repeat consumption.</li><li><a href="#Session-based Recommendation with Graph Neural Networks">Session-based Recommendation with Graph Neural Networks</a>: Model item transitions in sessions as a Graph.</li><li><a href="#Hierarchical Context enabled Recurrent Neural Network for Recommendation">Hierarchical Context enabled Recurrent Neural Network for Recommendation</a>: Emphasize global long-term interests, local sub-sequence interests and the temporary interests of each transition in a sequence.</li><li><a href="#A Spatio-Temporal Gated Network for Next POI Recommendation">A Spatio-Temporal Gated Network for Next POI Recommendation</a>: Emphasize the influence of spatio-temporal intervals between check-ins for POI recommendation.</li><li><a href="#Multi-order Attentive Ranking Model for Sequential Recommendation">Multi-order Attentive Ranking Model for Sequential Recommendation</a>: Emphasize the difference of individual-level and union level item relevance.</li></ol><h2 id="Cross-Domain-Recommendation"><a href="#Cross-Domain-Recommendation" class="headerlink" title="Cross Domain Recommendation"></a>Cross Domain Recommendation</h2><ol><li><a href="#Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems">Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems</a>: User more kinds of auxiliary info.</li><li><a href="#From Zero-Shot Learning to Cold-Start Recommendation">From Zero-Shot Learning to Cold-Start Recommendation</a>: Use ZSL method to solve CSR problem</li></ol><h2 id="Improve-Basic-Methods"><a href="#Improve-Basic-Methods" class="headerlink" title="Improve Basic Methods"></a>Improve Basic Methods</h2><ol><li><a href="#Holographic Factorization Machines for Recommendation">Holographic Factorization Machines for Recommendation</a>: Improve Factorization Machine (FM) with convolution operation.</li><li><a href="#Non-Compensatory Psychological Models for Recommender Systems">Non-Compensatory Psychological Models for Recommender Systems</a>: A novel method following the non-compensatory rules in consumer psychology while all traditional latent factor models fall into category of compensatory rules.</li><li><a href="#Discrete Social Recommendation">Discrete Social Recommendation</a>: To speedup models with quantization while maintain the performance as possible as we can.</li><li><a href="#A Unified Framework of Representation Learning and Matching Function Learning in Recommender System">A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</a>: A combination of two kinds conventional methods: representation learning based methods like MF and matching function learning based methods like NCF.</li></ol><h2 id="Specific-Tasks"><a href="#Specific-Tasks" class="headerlink" title="Specific Tasks"></a>Specific Tasks</h2><p>These methods utilize the information in some specific scenarios.</p><ol><li>POI recommendation as above</li><li><a href="#DAN: Deep Attention Neural Network for News Recommendation">DAN: Deep Attention Neural Network for News Recommendation</a>: Do a specific task with a complex combination of popular networks (actually news is just treated as text). The emphasized point is still the order info that has been studied for general recommendation over and over again.</li><li><a href="#Graph Augmented MEmory Networks for Recommending Medication Combination">Graph Augmented MEmory Networks for Recommending Medication Combination</a>: Also a specific task that recommends medication combination. The point is to process patient health history and drug-drug interactions with proper techniques. </li><li><a href="#An Integral Tag Recommendation Model for Textual Content">An Integral Tag Recommendation Model for Textual Content</a>: The authors emphasize three aspects of tag recommendation that impact the accuracy: 1) sequential text modeling. 2) tag correlation. 3) content-tag overlapping.</li><li><a href="#Hashtag Recommendation for Photo Sharing Services">Hashtag Recommendation for Photo Sharing Services</a>: Utilize info of image, text and personalized habits.</li><li><a href="#Joint Representation Learning for Multi-Modal Transportation Recommendation">Joint Representation Learning for Multi-Modal Transportation Recommendation</a>: Multi-Modal Transportation Recommendation. The main contribution is to format this problem while the method is simple.</li><li><a href="#Hierarchical Reinforcement Learning for Course Recommendation in MOOCs">Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</a>: Use RL to revise user profiles by removing the noisy courses instead of assigning an attention weight to each of them. The basic idea is independent from MOOCs but the author use info only in MOOCs to present state in RL.</li></ol><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ol><li><a href="#A Collaborative Ranking Method for Content Based Recommendation">A Collaborative Ranking Method for Content Based Recommendation</a>: Follow a traditional line that generates item embedding from auxiliary info and then combine it with MF like $u_i^T(v_j + embedding(doc_j))$</li><li><a href="#Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation">Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation</a>: A general formation of recommendation with user-item interaction, user-user relation(social relation), item-item relation.</li><li><a href="#Evaluating Recommender System Stability with Influence-Guided Fuzzing">Evaluating Recommender System Stability with Influence-Guided Fuzzing</a>: Predefine some modifications to modify the dataset and then evaluate the stability of some classical recommendation method.</li><li><a href="#Large-scale Interactive Recommendation with Tree-structured Policy Gradient">Large-scale Interactive Recommendation with Tree-structured Policy Gradient</a>: Construct all items as tree to reduce the time complexity of choosing an item from all items.</li><li><a href="#Meta Learning for Image Captioning">Meta Learning for Image Captioning</a></li><li>From Recommendation Systems to Facility Location Games: An interest aspect for recommendation problem. The authors design a Mediator (for service providers) to direct what the content providers(e.g. blog/video publishers) should provide to achieve overall higher social welfare while intervene as little as possible. The introduction of method is omitted for it is more related to social science and a bit complex.</li><li>Multi-Level Deep Cascade Trees for Conversion Rate Prediction in Recommendation: A problem related to recommendation. The problem want to predict conversion rate when users have clicked and viewed recommended items. Briefly, take Taobao for an example, conversion means users bought the recommended item after they clicked and viewed the item.</li></ol><h1 id="Session-based-Recommendation-with-Graph-Neural-Networks"><a href="#Session-based-Recommendation-with-Graph-Neural-Networks" class="headerlink" title="Session-based Recommendation with Graph Neural Networks"></a>Session-based Recommendation with Graph Neural Networks</h1><p>Problem: Session Recommendation</p><p>Gap: Transitions among distant items are often overlooked by previous methods. </p><p>Method: Use Graph to model item relation in sessions and utilize Graph Neural Networks to capturing transitions of items and generate accurate item embedding vectors. For example, as follows, the three sessions are constructed as a graph.</p><p><img src="/img/aaai19/session-graph.PNG" alt="Session graph"></p><h1 id="A-Collaborative-Ranking-Method-for-Content-Based-Recommendation"><a href="#A-Collaborative-Ranking-Method-for-Content-Based-Recommendation" class="headerlink" title="A Collaborative Ranking Method for Content Based Recommendation"></a>A Collaborative Ranking Method for Content Based Recommendation</h1><p>Problem: A traditional line that uses auxiliary information to enrich item embedding based on MF. The general score function for user $i$, item $j$ and auxiliary info $doc_j$ is as followings:<br>$$<br>f(i,j,doc_j) = p_i^T(q_j + g(doc_j))<br>$$<br>where $g(.)$ is the encoding function.</p><p>Gap: For function $g(.)$, some methods ignore the order of words, while others fail to identify the high leveled topic info.</p><p>Method: An encoding function based on GRU(capture order) and multi-head attention mechanism(model topic info).</p><p><img src="/img/aaai19/camo.PNG" alt="CAMO"></p><p>A Nice Attention Introduction: <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a></p><h1 id="Explainable-Reasoning-over-Knowledge-Graphs-for-Recommendation"><a href="#Explainable-Reasoning-over-Knowledge-Graphs-for-Recommendation" class="headerlink" title="Explainable Reasoning over Knowledge Graphs for Recommendation"></a>Explainable Reasoning over Knowledge Graphs for Recommendation</h1><p>Problem: recommendation with explainability, using KG specifically.</p><p>Gap: The connectivity information in KG can help to endow recommender systems the ability of reasoning and explainability. However, some traditional methods(use meta-paths) need domain knowledge to predefine meta-paths, while others(embedding based, like using TransE) are less explainable.</p><p>Method:</p><ol><li><p>Model user-item interaction $(u, i)$ as KG triplet relation $(u, interact, i)$.</p></li><li><p>For each $(u,i)$, select all paths from user node $u$ to item node $i$, denoted as $P(u,i) = {p_1, p_2, …, p_K}$</p></li><li><p>The score function from user $u$ to item $i$ is modeled as:<br>$$<br>\hat{y}<em>{ui} = f</em>{\Theta}(u,i|P(u,i))<br>$$</p></li><li><p>Use LSTM to model the preference of each path and use a weighted pooling layer(not attention) to calculate the final preference and estimate the importance of each path.</p><p><img src="/img/aaai19/kg-lstm.PNG" alt="kg-lstm"></p></li></ol><p>Weighted Pooling Layer:</p><p>For each preference $s_k$ outputted from the LSTM layer, the weighted pooling layer is defined as follows:<br>$$<br>g(s_1, s_2, …, s_K) = log[\sum_{k=1}^K \exp (\frac{s_K}{\gamma})]<br>$$<br>where $\gamma$ is a hyper-parameter to control each exponential weight and the path importance is estimated from the gradient on each path preference:<br>$$<br>\frac{\partial g}{\partial s_k} = \frac{\exp (s_k/ \gamma)}{\gamma \sum_{k^{‘}} \exp (s_{k^{‘}}/\gamma)}<br>$$<br>Finally,  the score function is<br>$$<br>y_{ui} = \sigma(g(s_1,s_2,…,s_K))<br>$$</p><h1 id="From-Zero-Shot-Learning-to-Cold-Start-Recommendation"><a href="#From-Zero-Shot-Learning-to-Cold-Start-Recommendation" class="headerlink" title="From Zero-Shot Learning to Cold-Start Recommendation"></a>From Zero-Shot Learning to Cold-Start Recommendation</h1><p>Problem: Cold-start Recommendation(CSR)</p><p>Gap: no gap but a novel view in light of Zero-Shot Learning(ZCL). Actually, I am not used to this kind of writing pattern.</p><p>Challenge to formulate CSR as a ZSL problem: </p><ol><li>Domain shift problem: the data distribution is not same as in ZSL</li><li>Data sparsity: the interactions in recommendation domain is very sparse.</li><li>Efficiency. </li></ol><p>Method: Use a Linear Low-rank Autoencoder to learn a transform matrix $W$ that transfer user behavior matrix $X$ into user attributes matrix $S$ as follows:<br>$$<br>\min_{W}|| X - W^TWX||<em>F^2 + \beta rank(W),  s.t. WX = S<br>$$<br>Then, for new users, we can estimate their potential user behavior matrix $X</em>{new}$ as<br>$$<br>X_{new} = W^TS_{new}<br>$$<br>My concern is how the autoencoder or low-rank constraint solve the data sparsity problem in Recommendation domain. In ZSL, each $X$ is an image with enough info. However, in RS, each $X$ is an interaction matrix which is very sparse and in total, there is only one large matrix with the user number as row number and item number as column number as train data. Compare to ZSL, the train dataset is also very small.</p><p>A similar low-rank Autoencoder for ZSL in IJCAI’18: <a href="https://www.ijcai.org/proceedings/2018/0345.pdf" target="_blank" rel="noopener">Zero Shot Learning via Low-rank Embedded Semantic AutoEncoder</a></p><h1 id="Meta-Learning-for-Image-Captioning"><a href="#Meta-Learning-for-Image-Captioning" class="headerlink" title="Meta Learning for Image Captioning"></a>Meta Learning for Image Captioning</h1><p>Problem: Image caption</p><p>Gap: reward hacking problem in RL. Shown in the following figure, the reward (digit next to the caption) of caption generated by RL is even higher than the ground truth (GT) caption while the caption quality is actually not.</p><p><img src="/img/aaai19/reward-hacking.PNG" alt="Reward hacking in image caption"></p><p>Method: Utilize the power of meta-learning to ensure the correctness and distinctiveness of the generated captions(by RL reward) and optimize the evaluation metrics(by maximizing the likelihood of the ground truth caption). Shown in the following graph, the meta-learning objective(marked in green) could the learn $\theta$ that is optimal to adapt both tasks while just adding RL reward $L_1(\theta)$ with maximize likelihood target $L_2(\theta)$takes a gradient in between (marked in brown).</p><p><img src="/img/aaai19/meta-loss-vs-aggregation.PNG" alt="meta loss vs aggregation"></p><p>The idea behind this work may suggest that we should use meta-learning optimization method to substitute trivial aggregation of different losses in all kinds of works if there is the similar hacking problem in the corresponding domains.</p><h1 id="Explainable-Recommendation-Through-Attentive-Multi-View-Learning"><a href="#Explainable-Recommendation-Through-Attentive-Multi-View-Learning" class="headerlink" title="Explainable Recommendation Through Attentive Multi-View Learning"></a>Explainable Recommendation Through Attentive Multi-View Learning</h1><p>Problem: recommendation with explainability</p><p>Gap: On one hand, some deep learning-based methods lack of explainability. On other hand, other shallow models lack of an effective mechanism to model high-level explicit features which limits their accuracy. What’s more they can’t identify hierarchical interests. As shown in the following graph, previous works can not identify whether a user is interested in lower-level features such as $\textit{shrimp}$ or higher-level features like $\textit{seafood}$.</p><p><img src="/img/aaai19/hierarchical-interests.PNG" alt="hierarchical interests"></p><p>Method: feed the model with the hierarchical features information. An overview is as follows.</p><ol><li>Build an explicit feature hierarchy $\gamma$ with in total $L$ features and $H$ layers from the collected data like <a href="https://concept.research.microsoft.com/" target="_blank" rel="noopener">Microsoft Concept Graph</a>. Pretrain with the graph to get the embedding $e_i$ of each feature node.</li><li>For a user $i$,  collect his explicit user-feature interest $x_i$ from his reviews. $x_{il}$ indicates the frequence of the feature $F_l$ being mentioned by the user.</li><li>propagate the feature-interest on the tree to get more proper interest $\hat{x_i}$ to let each interest on the feature node contain the interests on its sub-nodes. </li><li>For items, build their features denoted as $\hat{y_j}$ from product introduction in a similar way. </li><li>Attentive multi-view learning with the ratings and collected features as supervising info. Each user and item has an implicit feature and an explicit feature. Both features need fit ratings based on MF while the explicit features need also  fit collected features with a linear transform and L2 loss.</li></ol><p>The overall process is as follows.</p><p><img src="/img/aaai19/multi-view-learning.PNG" alt=""></p><p>Then for explainability, the method utilize the feature hierarchy $\gamma$ and the trained model to select some important features as reason of recommendation.</p><p>Additionally, from the experimental results shown in the following figure, we can see SVD++ performs well with RMSE metric and even performs better than some deep models likes DeepCoNN and NARRE that using review info. The phenomenon should be discussed more detailly.</p><p><img src="/img/aaai19/multi-view-learning-exp.PNG" alt=""></p><h1 id="Dynamic-Explainable-Recommendation-based-on-Neural-Attentive-Models"><a href="#Dynamic-Explainable-Recommendation-based-on-Neural-Attentive-Models" class="headerlink" title="Dynamic Explainable Recommendation based on Neural Attentive Models"></a>Dynamic Explainable Recommendation based on Neural Attentive Models</h1><p>Problem: recommendation with explainability</p><p>Gap: Most previous works represent a user as a static latent vector($most$ is a good word). More importantly, <em>the explanations provided by these models are usually invariant</em>.</p><p>Method: Use GRU to model dynamic interest of users. Add a time gate to GRU to use the message of time interval. For example, a user tend to have similar preferences within a short time, while large time gap may have more opportunities to change user interest. For an item, use the hidden state $h_s$ of GRU at current time as the user’s interest to select the most related sentence in the reviews as explanation by making use of attention mechanism. The general process is shown in following figure.</p><p><img src="/img/aaai19/dynamic-gru.PNG" alt=""></p><p>An example of explanation is shown as follows.</p><p><img src="/img/aaai19/dynamic-explanation-demo.PNG" alt=""></p><h1 id="DAN-Deep-Attention-Neural-Network-for-News-Recommendation"><a href="#DAN-Deep-Attention-Neural-Network-for-News-Recommendation" class="headerlink" title="DAN: Deep Attention Neural Network for News Recommendation"></a>DAN: Deep Attention Neural Network for News Recommendation</h1><p>Problem: News recommendation (next item recommendation)</p><p>Gap: They usually fail with the dynamic diversity of news and user’s interests, or ignore the importance of sequential information of user’s clicking selection. (This is obviously a false assertion for general recommendation) </p><p>Method: Combination of CNN, RNN and Attention Mechanism. </p><p><img src="/img/aaai19/news-rec.PNG" alt=""></p><p>As shown in the above figure, the process is summary as:</p><ol><li><p>Use two CNN(PCNN) to extract embedding of news with title and profile parts.</p></li><li><p>Use LSTM and Attention to learn a user’s embedding with a sequence of clicked news.</p></li><li><p>Score function is based on similarity between user embedding and candidate news embedding as follows. The $cosine$ function is calculated by the inner product of two vectors which is the same with MF but with different name.<br>$$<br>P = cosine(\hat{I}_t . I_t)<br>$$</p></li></ol><h1 id="A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation"><a href="#A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation" class="headerlink" title="A Repeat Aware Neural Recommendation Machine for Session-based Recommendation"></a>A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</h1><p>Problem: session recommendation</p><p>Gap: propose a novel <em>repeat consumption</em> phenomenon where the same item is re-consumed repeatedly over time. The following table shows the repeat ratio in three public datasets.  However, no previous works have emphasized <em>repeat consumption</em> with neural networks. (Multi-armed bandit problem has been studied for a long time to solve the repeat-explore dilemma for general recommendations.)</p><p><img src="/img/aaai19/repeat-ratio.PNG" alt=""></p><p>Method: </p><p><img src="/img/aaai19/repeatnet.PNG" alt=""></p><p>As shown in the above figure, the process is summarized as:</p><ol><li>Use GRU to encode the session sequence of a user.</li><li>Use attention mechanism to merge all hidden states with the last hidden state as attention point. Then use a dense network to transform the merged vector into a two dimension vector with the first value as the probability of <em>repeat</em> and the other as the probability of <em>explore</em></li><li>For repeat mode, decode the hidden states to calculate score for each item (new items get 0 point)</li><li>For explore mode, decode the hidden states with attention to calculate for each item (old items get 0 point)</li><li>Use the score and whether the item is new as supervising info to train model with a negative log-likelihood loss and a logistic loss.</li></ol><h1 id="Hierarchical-Context-enabled-Recurrent-Neural-Network-for-Recommendation"><a href="#Hierarchical-Context-enabled-Recurrent-Neural-Network-for-Recommendation" class="headerlink" title="Hierarchical Context enabled Recurrent Neural Network for Recommendation"></a>Hierarchical Context enabled Recurrent Neural Network for Recommendation</h1><p>Problem: Next-item recommendation</p><p>Gap: Emphasize long-term interests, local sub-sequence interests and temporary interests of each transition which are shown in the following graph while all these interests have only been partially reflected in most previous works.</p><p><img src="/img/aaai19/sequential-interest.PNG" alt=""></p><p>Method: (the authors assume each sequence should be longer than 10 in experiments)</p><p>Traditional LSTM process is shown as follows:</p><p><img src="/img/aaai19/hcrnn-lstm.PNG" alt=""></p><p>The authors propose to use cell state $c_t$ to present the local-sub sequence interests and use hidden state $h_t$ to present temporary transition interests. However, in traditional LSTM, $h_t$ are only directly dependent on $c_t$, there is little difference between them. Besides the long-term interests are neglected if $c_t$ is treated only as local interest. So, the author modify to LSTM to let $h_t$ more independent and add a memory network to keep long-term interests. The process is shown as </p><p><img src="/img/aaai19/hcrnn-1.PNG" alt=""></p><p>where the parameter $\theta$ are trainable parameter $\theta$ for attention mechanism. Then in each transition, the influence of global long-term interests is considered.</p><p>The general process is shown in the following graph in which other tricks like bi-channel attention for prediction to focus on all interests are simply demonstrated.</p><p><img src="/img/aaai19/hcrnn-arch.PNG" alt=""></p><p>One way to demonstrate global interests is shown in the following graph from which we can see global context vector cover the most of the items.</p><p><img src="/img/aaai19/hcrnn-embedding.PNG" alt=""></p><h1 id="A-Spatio-Temporal-Gated-Network-for-Next-POI-Recommendation"><a href="#A-Spatio-Temporal-Gated-Network-for-Next-POI-Recommendation" class="headerlink" title="A Spatio-Temporal Gated Network for Next POI Recommendation"></a>A Spatio-Temporal Gated Network for Next POI Recommendation</h1><p>Problem: POI recommendation (next item prediction)</p><p>Gap: Most previous recommendation methods don’t consider both time intervals and geographical distances between neighbor items that are shown in bellowing figure. And some other methods may fail to model spatial and temporal relations of neighbor check-ins properly (see paper for more detail discussion).</p><p><img src="/img/aaai19/poi-intervals.PNG" alt=""></p><p>Method: </p><p><img src="/img/aaai19/poi-lstm.PNG" alt=""></p><p>Shown in the above figure, based on LSTM, the authors also add two time interval gates and  two distance gates (no direction info) besides the input gate.</p><p><img src="/img/aaai19/poi-gates.PNG" alt=""></p><p>Gates $T1, D1$ are used to  filter new information considering influence of time interval and distance and then the filtered information is transferred to the hidden state and finally influences the next recommendation. Gates $T2, D2$ are used in a similar way for estimating new cell state.</p><h1 id="Multi-order-Attentive-Ranking-Model-for-Sequential-Recommendation"><a href="#Multi-order-Attentive-Ranking-Model-for-Sequential-Recommendation" class="headerlink" title="Multi-order Attentive Ranking Model for Sequential Recommendation"></a>Multi-order Attentive Ranking Model for Sequential Recommendation</h1><p>Problem: Next item recommendation</p><p>Gap: Except for the individual-level relevance, union-level item relevance also influence a user’s interactions. For example, buying eggs, milk, and butter together indicates a higher probability of buying flour than eggs, milk or butter individually.  However, most previous works neglected the union-level relevance and others didn’t model it well (see paper for more detail discussion). The following figure shows two kinds of relevance.</p><p><img src="/img/aaai19/union-relevance.PNG" alt=""></p><p>Method: To predict the score of item $j$ for a user $u$, the authors also directly add the influence of the items, denote as a set $S_{t-1,n}^u$, that the user has interacted with recently. Then the final prediction is estimated as<br>$$<br>\hat{y}_{u,j} = p_uq_j^T + F(u, S_{t-1,n}^u)m_j^T<br>$$<br>Then the point is how to model the union-level preference $F(u, S_{t-1,n}^u)$.</p><p><img src="/img/aaai19/union-arch.PNG" alt=""></p><p>Generally, shown in the left of the above figure, the authors use the user feature $p_u$ as the attention point to decide the weight of each item $S_{t-1,n}^u$ with as special Multi-order Attention Network (see paper for detail). The the output, denoted as $e_c$, of the Attention Network could regard as the individual-level influence of the items in $S_{t-1,n}^u$ to the target item $j$ with each item with different attention weight. To capture the union-level influence, the authors add a L-layer ResNet to fuse the influence in $e_c$ to a high-level feature, denoted as $h_L$. Finally the feature $F(u, S_{t-1,n}^u)$ is $e_c + h_L$.</p><h1 id="Graph-Augmented-MEmory-Networks-for-Recommending-Medication-Combination"><a href="#Graph-Augmented-MEmory-Networks-for-Recommending-Medication-Combination" class="headerlink" title="Graph Augmented MEmory Networks for Recommending Medication Combination"></a>Graph Augmented MEmory Networks for Recommending Medication Combination</h1><p>Problem: Recommend medication combination, a special specific task</p><p>Gap: Existing approaches either do not customize based on patient health history, or ignore existing knowledge on drug-drug interactions (DDI) that might lead to adverse outcomes.  </p><p>Method: The method is a bit complex in actual. Briefly:</p><ol><li><p>Use Graph to represent the DDI relation and the estimated drug combination relation from patient health history.</p></li><li><p>Use GCN (Graph Convolutional Network) to learn Graph node representations and then format them as two memory networks: 1) memory bank (MB): the key and value are both node embeddings. 2) dynamic memory (DM): the key is embedding of  a user’s historical diseases (learned as follows)  before current time and the value the the corresponding medication combination.</p></li><li><p>Use RNN to learn embeddings of a user’s  historical diseases at each time, denoted as $q_t$.</p></li><li><p>Use $q_t$ as query vector to query the two memories built as above and use the collected memory to do a multi-label classification to recommend medication combination</p></li><li><p>Besides the traditional multi-label classification loss, the authors also add a DDI loss to avoid drug-drug -interactions like follows where $A_d[i,j] = 1$ if drug $i$ has an interaction on drug $j$<br>$$<br>L_{DDI} = \sum_t^T \sum_{i,j}(A_d \odot (\hat{y}_t^T\hat{y_t}))[i,j]<br>$$</p></li><li><p>Additionally, the authors use a special combined loss functions in medication instead of weighted aggregation</p><p><img src="/img/aaai19/drug-loss.PNG" alt=""></p><p>Finally, the overall architecture is shown in the following figure. A users’ historical disease consists of two parts. One is the diagnoses code $c_d^t$ and the other is the procedure code $c_p^t$ </p><p><img src="/img/aaai19/drug-arch.PNG" alt=""></p></li></ol><h1 id="Deeply-Fusing-Reviews-and-Contents-for-Cold-Start-Users-in-Cross-Domain-Recommendation-Systems"><a href="#Deeply-Fusing-Reviews-and-Contents-for-Cold-Start-Users-in-Cross-Domain-Recommendation-Systems" class="headerlink" title="Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems"></a>Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems</h1><p>Problem: Cross-Domain Recommendation for cold-start users.</p><p>Gap: Most existing cross-domain recommendation works still do not take full consideration of different kinds of valuable side information (In this paper, there are two kinds of information: review texts and item contents).</p><p>Method:</p><p><img src="/img/aaai19/cross-domain-arch.PNG" alt=""></p><p>The framework is shown as above, the brief process is summarized as:</p><ol><li>For both domain, the text info of a user is all of his review texts, the text info for a item is all reviews on it. Besides, in auxiliary domain, the text info of item also includes item contents. </li><li>Use Stacked Denoising Autoencoders to encoding a user according to his/her ratings on all items with the text info as a side info (like AUR_u in the left bottom). Learn the representations of items in a similar way except for items in auxiliary domain that also utilize item contents (AIP_i(A) in upper center)</li><li>Use MF to predict ratings in both domain</li><li>Use MLP to transfer the features in auxiliary domain to target domain.</li></ol><p>My concern is that the MLP part only tunes parameters of MLP based on this transform method. In another word, the features of users and items should be pretrained. Then the pretraining of $U$ and $V$ to let them prepared for the transform part will be a hard work utilizing only the sparse rating matrices. Instead, the pretraining works in other domain like NLP and CV usually need a very large dataset.</p><h1 id="Discrete-Social-Recommendation"><a href="#Discrete-Social-Recommendation" class="headerlink" title="Discrete Social Recommendation"></a>Discrete Social Recommendation</h1><p>Problem: social recommendation</p><p>Gap: With traditional methods like MF, the large volume of user/item latent features results in expensive storage and computation cost, particularly on terminal user devices where the computation resource to operate model is very limited. Besides, some quantization methods(use lower precision values, e.g. 2-bit int vector instead of 32-bit float vector) would lose accuracy after the model has been trained.</p><p>Method: To learn binary vector as features of users and items.</p><p><img src="/img/aaai19/binary-vector.PNG" alt=""></p><p>Shown in the above figure, the idea is simple. All feature vectors $b_i, d_j, f_k$ are binary vectors. Here $S$ is the social relation between users and $f_k$ is a third latent feature (different from $b_k$).</p><p>The challenge is how to optimize this problem. The problem is a little similar with NMF, but this problem has much more constraint conditions. See the original paper for detail optimizing method if you are interested.</p><p>The following figures show the performance and time cost. DSR is the proposed model and r is code length.</p><p><img src="/img/aaai19/dsr-exp1.PNG" alt=""></p><p><img src="/img/aaai19/dsr-exp2.PNG" alt=""></p><h1 id="A-Unified-Framework-of-Representation-Learning-and-Matching-Function-Learning-in-Recommender-System"><a href="#A-Unified-Framework-of-Representation-Learning-and-Matching-Function-Learning-in-Recommender-System" class="headerlink" title="A Unified Framework of Representation Learning and Matching Function Learning in Recommender System"></a>A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</h1><p>Problem: Traditional recommendation problem.</p><p>Gap: Divide traditional methods into two types. One is representation learning based like MF and the other is matching function learning based like NCF. The authors combine these two kinds of methods.</p><p>Method:</p><p><img src="/img/aaai19/deep-cf.PNG" alt=""></p><p>In my view, the method is under NCF framework. However, different from NCF, the representation of users and items are not randomly initialized but learning by two representation function $f$ and $g$ from raw ratings.</p><p>The method is simple. But the difficult point is to train a deep network with sparse ratings in which the model is easy to be overfitting.</p><h1 id="An-Integral-Tag-Recommendation-Model-for-Textual-Content"><a href="#An-Integral-Tag-Recommendation-Model-for-Textual-Content" class="headerlink" title="An Integral Tag Recommendation Model for Textual Content"></a>An Integral Tag Recommendation Model for Textual Content</h1><p>Problem: Tag recommendation</p><p>Gap:  An example of tags to a text is shown in the following graph. The authors emphasize three aspects of tag recommendation that impact the accuracy: 1) sequential text modeling. This a common aspect. 2) tag correlation. The tags for a text are usually related with each other. 3) content-tag overlapping. Tags are often overlapped with the word in  original text.  However, there lacks an integral method that captures all the three aspects with a coherent model.</p><p><img src="/img/aaai19/tag-demo.PNG" alt=""></p><p>Method:</p><p><img src="/img/aaai19/tag-arch.PNG" alt=""></p><p>As shown in the above figure, the authors use an Multi-Layer GRU as an Encoder to encode the original text and another Multi-layer GRU as a Decoder to generate tags.</p><ol><li><p>GRU could capture the order info in text</p></li><li><p>During decoding process, the previous output tag is used as the input to predict next tag. In this way, the network could capture tag correlation info.</p></li><li><p>Use a shared embedding layer to learn representation of text and tags in the same space. Besides, the author add an Indicator Function to explicitly  indicate the probability of directly copying a word from the content as the tag. The probability of copying a word is calculate as<br>$$<br>o_i = v_2^T. \tanh (W_3.s_i) \<br>p_i = \sigma(o_i)<br>$$<br>where $s_i$ is the overall content representation for predicting current tag. $v_2$ and $W_3$ are parameters.</p></li><li><p>Finally, the probability of a tag a is combination of probability of recommending a new tag and copying a word.<br>$$<br>P^{‘}(z_i) = (1-p_i)(p(z_i)) + p_i . \alpha(z_i)<br>$$<br>where $\alpha(z_i)$ is the attention weight of each word in the original text.</p></li></ol><h1 id="Hashtag-Recommendation-for-Photo-Sharing-Services"><a href="#Hashtag-Recommendation-for-Photo-Sharing-Services" class="headerlink" title="Hashtag Recommendation for Photo Sharing Services"></a>Hashtag Recommendation for Photo Sharing Services</h1><p>Problem: Hashtag recommendation for photo sharing services</p><p>Gap: In this scenario, each photo post has a text description and each user has some historical posts with tags. So previous methods failed to capture all of image info, text info and personalized user habits in an integral model.</p><p>Method:</p><p><img src="/img/aaai19/photo-tag-arch.PNG" alt=""></p><p>As shown in above figure, the general process is summarized as follows:</p><ol><li>Use a co-attention based Post Feature Extraction that considers the co-influence of image and text to extract Post Feature.</li><li>Use Post Feature $p$ as attention point to extract representation of related tags in a user’s historical post, denoted as Influence Vector $t$</li><li>Concatenate content feature $p$ and personal habit $t$ as the Overall Feature to give the final prediction.</li></ol><p>Again, A Nice Attention Introduction: <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a></p><h1 id="Holographic-Factorization-Machines-for-Recommendation"><a href="#Holographic-Factorization-Machines-for-Recommendation" class="headerlink" title="Holographic Factorization Machines for Recommendation"></a>Holographic Factorization Machines for Recommendation</h1><p>Problem: Recommendation basic methods</p><p>Gap: A new Holographic Factorization Machines based on FM utilizing the power of  Holographic Reduced Representation.</p><p>Method: In a simply word, the authors use circular convolution operator to replace the inner product operator in FM.</p><p>FM:</p><p><img src="/img/aaai19/hfm-fm.PNG" alt=""></p><p>HFM:</p><p><img src="/img/aaai19/hfm.PNG" alt=""></p><p>where $L(x) = w_0 + \sum_{i=1}^nw_ix_i$ and circular convolution operator(here $a$ and $b$ are both vectors other than matrix in CNN) is defined as</p><p><img src="/img/aaai19/hfm-convolution.PNG" alt=""></p><h1 id="Evaluating-Recommender-System-Stability-with-Influence-Guided-Fuzzing"><a href="#Evaluating-Recommender-System-Stability-with-Influence-Guided-Fuzzing" class="headerlink" title="Evaluating Recommender System Stability with Influence-Guided Fuzzing"></a>Evaluating Recommender System Stability with Influence-Guided Fuzzing</h1><p>Problem: Evaluate the stability of Recommender System</p><p>Gap: A new aspect. The idea is similar to adversary examples in CV, but the problem is proposed independently in the paper. The authors design a method (Influence-Guided Fuzzing) to find small sets of modifications (add, remove, change)  to train data that cause significantly instability of some recommendation methods.</p><p>Method: Influence-Guided Fuzzing</p><ol><li><p>Inferring Influence: The authors define four kinds of <em>influence</em> to measure the impact of <em>user</em>, <em>item</em>, <em>attribute</em> and <em>rating</em> on recommendations.</p></li><li><p>Based on the <em>influence</em> defined above, the author defines some modifications to the dataset shown in the following table.</p><p><img src="/img/aaai19/influence-fuzzing.PNG" alt=""></p></li><li><p>Finally, the authors apply these modifications to the dataset and test the result.</p></li></ol><p>This heuristics method defines a lot modifications which are not as elegant as the gradient-based adversary examples in CV.</p><h1 id="Joint-Representation-Learning-for-Multi-Modal-Transportation-Recommendation"><a href="#Joint-Representation-Learning-for-Multi-Modal-Transportation-Recommendation" class="headerlink" title="Joint Representation Learning for Multi-Modal Transportation Recommendation"></a>Joint Representation Learning for Multi-Modal Transportation Recommendation</h1><p>Problem: Multi-modal transportation recommendation</p><p>Gap: Most previous works focus on improving unimodal transport planning.</p><p>Challenges to do multi-modal transportation recommendation:</p><ol><li>transport heterogeneity</li><li>incomplete and implicit feedbacks</li><li>geo-spatial locality</li></ol><p>Method: </p><p><img src="/img/aaai19/trans-framework.PNG" alt=""></p><p>Firstly, a lot of work is to format data. As shown in the above figure, the authors build a MMTG (Multi-modal Transportation Graph) from all kinds of raw data. An example of MMTG is shown in the following figure.</p><p><img src="/img/aaai19/trans-mmtg.PNG" alt=""></p><p>Three kinds of nodes: Users, Transport modes, OD(Origin-Destination) pairs.</p><p>Four kinds of edges: user-user, user-mode, mode-od, od-od</p><p>Then the personalized recommendation task is formulated as:</p><ol><li><p>The data is a set of historical travel event, denote as $&lt;u,m,od&gt;$ where $u, m, od$ are user, mode and OD pair. Then given a new $&lt;u, od&gt;$, we want to recommend a most appropriate mode $m$.</p></li><li><p>Logistic loss with negative sampling</p><p><img src="/img/aaai19/trans-loss.PNG" alt=""></p></li></ol><p>The method is simple and the contribution is to format the complex problem. </p><h1 id="Hierarchical-Reinforcement-Learning-for-Course-Recommendation-in-MOOCs"><a href="#Hierarchical-Reinforcement-Learning-for-Course-Recommendation-in-MOOCs" class="headerlink" title="Hierarchical Reinforcement Learning for Course Recommendation in MOOCs"></a>Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</h1><p>Problem: Course Recommendation in MOOCs</p><p>Gap: For previous attention-based works, when a user has interests in many different courses, the attention mechanism will perform poorly as the effects of the contributing courses are diluted by diverse historical courses.  An example is shown in the following figure, for a trained attention-based model, the real target course get lower recommendation probability than a random selected course although it give more related courses more weights.</p><p><img src="/img/aaai19/course-intuition.PNG" alt=""></p><p>More analyses on dataset is shown in the following figure. From figure (b), we can the category ratio is evenly distributed for all users. From figure (c), we can see as the category ratio grows larger which means these users like more kinds of courses, a trained attention-based model give lower recommendation probability to the target courses.</p><p><img src="/img/aaai19/course-data.PNG" alt=""></p><p>Method: Use RL to revise user profiles by removing the noisy courses instead of assigning an attention weight to each of them.</p><p><img src="/img/aaai19/course-arch.PNG" alt=""></p><p>As shown in the above figure, the process is briefly summarized as:</p><ol><li>Use a two level Markov Decision Process(MDP) to decide how to revise the original profile. Firstly, a high level MDP to decide whether to revise the profile. Then if the high level MDP decides to revise the profile, a low level MDP will decide how to revise the profile. Finally the revised profile (maybe no change) will delivered to a basic recommendation model for training.</li><li>The reward R to decide how to revise current profile is the difference of recommendation probabilities using revised profile and original profile. The internal reward G is the difference of similarity between (revised profile, target course) and similarity between (original profile, target course)</li></ol><p>Other details is omitted here.</p><h1 id="Non-Compensatory-Psychological-Models-for-Recommender-Systems"><a href="#Non-Compensatory-Psychological-Models-for-Recommender-Systems" class="headerlink" title="Non-Compensatory Psychological Models for Recommender Systems"></a>Non-Compensatory Psychological Models for Recommender Systems</h1><p>Problem: Basic recommendation method</p><p>Gap: A novel aspect. The study of consumer psychology reveals two categories of consumption decision procedures: compensatory rules and non-compensatory rules. Under compensatory rules a consumer evaluates an item over all relevant aspects  and a good performance on one aspect of an item compensates for poor performances on other aspects. So all traditional latent factor based methods fall into the category of compensatory rules. However, in the study of human choice behavior, it is well regarded that consumers more frequently make consumption related choice based on non-compensatory rules which do not allow the shortcomings of a product be balanced out by its attractive features. So the authors propose a method based on non-compensatory rules.</p><p>Method:</p><p>Introduction of some non-compensatory rules:</p><ol><li>Lexicographic rule: this rules assumes that aspects of products can be ordered in terms of importance and alternative brands are evaluated sequentially from the most prominent to the least prominent aspects.</li><li>Conjunctive rule: This rule establishes a minimally acceptable the acceptable threshold for each aspect.</li></ol><p>Model framework:</p><p><img src="/img/aaai19/nc-framework.PNG" alt=""></p><p>As shown in above figure, the authors assume a user’s preference on all aspects consists of two parts: prominent aspect and non-prominent part. For evaluation on prominent aspect, the score should be maximized while for evaluation on non-prominent aspects, the scores just need to satisfy some thresholds.</p><p>Following this idea, the authors changes many traditional models like MF, AMF, Local Low-rank MF, BPR. Here we take MF for an example to illustrate the work.</p><p>For traditional MF, the predicted score $\hat{X}<em>{u,q}$ for user vector $u$ and item vector (v) is calculated as:<br>$$<br>\hat{X}</em>{u,q} = \sum_{k=1}^Kq_ku_k<br>$$<br>where $K$ is dimension of latent factors.</p><p>Then under non-prominent rules, preference $u$ represents the a distribution of whether each aspect is a prominent aspect or not. Then for MF, the author firstly sample a prominent aspect from u as:<br>$$<br>k \sim \frac{\exp u_k}{\sum_{k^{‘}}\exp u_{k^{‘}}}<br>$$<br>Then the prominent aspect is magnified by parameter $\exp \theta$ and the non-prominent aspect should satisfy a threshold $b_{u,k^{‘}}$. Finally, the overall evaluation score is calculated as:<br>$$<br>\hat{X}<em>{u,q} = \sum</em>{k=1}^K\frac{\exp u_K}{\sum_{k^{‘}}\exp u_{k^{‘}}}[q_k\exp\theta + \sum_{k^{‘} \neq k}(q_{k^{‘}} - b_{u,k^{‘}})]<br>$$</p><h1 id="Modeling-Influential-Contexts-with-Heterogeneous-Relations-for-Sparse-and-Cold-Start-Recommendation"><a href="#Modeling-Influential-Contexts-with-Heterogeneous-Relations-for-Sparse-and-Cold-Start-Recommendation" class="headerlink" title="Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation"></a>Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation</h1><p>Problem: Recommendation with influential contexts(social relation and item-item relation)</p><p>Gap: </p><p><img src="/img/aaai19/context-intuition.PNG" alt=""></p><p>As shown in above figure, the authors format a general recommendation with influential contexts(social relation and item-item relation) and user-item interaction. In this view, most previous works have only partially considered this problem with info of at most two relations.</p><p>Method:</p><p><img src="/img/aaai19/context-arch.PNG" alt=""></p><p>The general process is clearly shown in the above figure. The Representers $E$ is just latent embedding. The Aggregator of user has two level of modules based attention(capturing influence of friends’ friends). The Aggregator of item has only one level attention network. Finally, the User-item Interaction is inner product.</p><p>In this way, the final score contains influence of four parts as follows:</p><p><img src="/img/aaai19/context-score.PNG" alt=""></p><p>where in order the influence of four parts are: user - item, user - item context, user context - item, user context - item context.</p><h1 id="Large-scale-Interactive-Recommendation-with-Tree-structured-Policy-Gradient"><a href="#Large-scale-Interactive-Recommendation-with-Tree-structured-Policy-Gradient" class="headerlink" title="Large-scale Interactive Recommendation with Tree-structured Policy Gradient"></a>Large-scale Interactive Recommendation with Tree-structured Policy Gradient</h1><p>Problem: Interactive Recommendation (here the definition is more similar to online recommendation)</p><p>Gap: With a large number of items, traditional RL methods that handle the problem with linear time complexity is not efficient enough. </p><p>Method: Tree-structed Policy Gradient.</p><p><img src="/img/aaai19/irs-tree.PNG" alt=""></p><p>As shown in the above figure, the authors build a tree of items according to similarities of different items. Then the decision process of choosing a item is finding a path on the tree(about logN complexity) instead of finding one item from all items(N complexity)</p><p>Complexity of finding a path on the tree:</p><p>The depth of the tree is denoted as d, and each node has at most c children. Then the complexity of making  decision in each Policy Network is as most c. Then total complexity is d*c which is approximately equal to logN.</p><p>The performance of this method highly depend on the quality of the built tree. The authors use three ways to represent each item as an vector and then user clustering method to cluster all items level by level to build the tree.</p><ol><li>Raw rating vector.</li><li>latent factors of MF</li><li>Use VAE to encode raw rating vector.</li></ol><p>My concern is all these three ways are hard to learn a good representation with sparse ratings.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/img/aaai19/overview.PNG&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Recommender Systems" scheme="https://n4a.github.io/tags/Recommender-Systems/"/>
    
      <category term="Knowledge graph" scheme="https://n4a.github.io/tags/Knowledge-graph/"/>
    
      <category term="RNN" scheme="https://n4a.github.io/tags/RNN/"/>
    
      <category term="Attention Mechanism" scheme="https://n4a.github.io/tags/Attention-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>Paper_Notes_About_Recommendation_in_SIGIR18</title>
    <link href="https://n4a.github.io/2019/05/14/Paper-Notes-About-Recommendation-in-SIGIR18/"/>
    <id>https://n4a.github.io/2019/05/14/Paper-Notes-About-Recommendation-in-SIGIR18/</id>
    <published>2019-05-14T08:08:15.000Z</published>
    <updated>2019-09-10T08:59:14.219Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>•Online recommendation(1)</p><p>•Recommendation with Social Networks(2+1)</p><p>​    Group representation, community detection, sequence-aware Rec</p><p>•Recommendation with Knowledge Base(1)</p><p>•Improve traditional methods(3)</p><p>​    APR, CMN, Bandit problem</p><p>•Some specific tasks(5)</p><p>​    Recommend email, mention, citation, Wikipedia article section</p><p>​    Conversational recommender system</p><p>​    User modeling: Geo-social based(1)</p><a id="more"></a><h1 id="PPT-1"><a href="#PPT-1" class="headerlink" title="PPT 1"></a>PPT 1</h1><div class="row">    <embed src="/pdf/SIGIR18_Papers_about_Recommendation.pdf" width="100%" height="550" type="application/pdf"></div><h1 id="PPT-2"><a href="#PPT-2" class="headerlink" title="PPT 2"></a>PPT 2</h1><div class="row">    <embed src="/pdf/SIGIR18_Papers_about_Recommendation2.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;p&gt;•Online recommendation(1)&lt;/p&gt;
&lt;p&gt;•Recommendation with Social Networks(2+1)&lt;/p&gt;
&lt;p&gt;​    Group representation, community detection, sequence-aware Rec&lt;/p&gt;
&lt;p&gt;•Recommendation with Knowledge Base(1)&lt;/p&gt;
&lt;p&gt;•Improve traditional methods(3)&lt;/p&gt;
&lt;p&gt;​    APR, CMN, Bandit problem&lt;/p&gt;
&lt;p&gt;•Some specific tasks(5)&lt;/p&gt;
&lt;p&gt;​    Recommend email, mention, citation, Wikipedia article section&lt;/p&gt;
&lt;p&gt;​    Conversational recommender system&lt;/p&gt;
&lt;p&gt;​    User modeling: Geo-social based(1)&lt;/p&gt;
    
    </summary>
    
    
      <category term="Attention" scheme="https://n4a.github.io/tags/Attention/"/>
    
      <category term="Recommender System" scheme="https://n4a.github.io/tags/Recommender-System/"/>
    
      <category term="Social Network" scheme="https://n4a.github.io/tags/Social-Network/"/>
    
  </entry>
  
  <entry>
    <title>Paper summary_work based on meta learning</title>
    <link href="https://n4a.github.io/2018/12/30/Paper-summary-work-based-on-meta-learning/"/>
    <id>https://n4a.github.io/2018/12/30/Paper-summary-work-based-on-meta-learning/</id>
    <published>2018-12-30T13:55:17.000Z</published>
    <updated>2018-12-30T14:06:07.178Z</updated>
    
    <content type="html"><![CDATA[<ol><li>Meta Learning Framework</li><li>ProtoNet: 一个和 Matching Net 十分相似的处理 few shot learning 任务的<br>模型</li><li>MAML: MAML 模型通过 Meta learning 的方法，尝试为所有的子任务学<br>习一个初始参数，使得各个子任务能够在该参数基础上快速收敛。</li><li>Meta learning for unsupervised learning: 一种利用 meta learning 框架来使<br>用无标签数据的方法。</li><li>Meta learning for item cold-start recommendation: Meta learning 在物品冷<br>启动任务中的一个应用。 </li></ol><a id="more"></a><div class="row">    <embed src="/pdf/Meta_learning_Paper_summary.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;Meta Learning Framework&lt;/li&gt;
&lt;li&gt;ProtoNet: 一个和 Matching Net 十分相似的处理 few shot learning 任务的&lt;br&gt;模型&lt;/li&gt;
&lt;li&gt;MAML: MAML 模型通过 Meta learning 的方法，尝试为所有的子任务学&lt;br&gt;习一个初始参数，使得各个子任务能够在该参数基础上快速收敛。&lt;/li&gt;
&lt;li&gt;Meta learning for unsupervised learning: 一种利用 meta learning 框架来使&lt;br&gt;用无标签数据的方法。&lt;/li&gt;
&lt;li&gt;Meta learning for item cold-start recommendation: Meta learning 在物品冷&lt;br&gt;启动任务中的一个应用。 &lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Machine learning" scheme="https://n4a.github.io/tags/Machine-learning/"/>
    
      <category term="Meta learning" scheme="https://n4a.github.io/tags/Meta-learning/"/>
    
      <category term="ML" scheme="https://n4a.github.io/tags/ML/"/>
    
      <category term="few-shot learning" scheme="https://n4a.github.io/tags/few-shot-learning/"/>
    
  </entry>
  
  <entry>
    <title>BP derivation for MLP and CNN</title>
    <link href="https://n4a.github.io/2018/12/14/BP-derivation-for-MLP-and-CNN/"/>
    <id>https://n4a.github.io/2018/12/14/BP-derivation-for-MLP-and-CNN/</id>
    <published>2018-12-14T07:26:08.000Z</published>
    <updated>2018-12-14T07:29:10.385Z</updated>
    
    <content type="html"><![CDATA[<p>\section{Task description}<br>Please derive a backpropagation process</p><p>(1)   for the multi-layer neural network with one hidden layer, where data are in a m-dimensional feature space with n classes. Loss functions can use L2 distance or cross entropy.</p><p>(2)   for the LeNet-5 CNN.  </p><a id="more"></a><div class="row">    <embed src="/pdf/bp-derivation-mlp.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;\section{Task description}&lt;br&gt;Please derive a backpropagation process&lt;/p&gt;
&lt;p&gt;(1)   for the multi-layer neural network with one hidden layer, where data are in a m-dimensional feature space with n classes. Loss functions can use L2 distance or cross entropy.&lt;/p&gt;
&lt;p&gt;(2)   for the LeNet-5 CNN.  &lt;/p&gt;
    
    </summary>
    
    
      <category term="BP" scheme="https://n4a.github.io/tags/BP/"/>
    
      <category term="MLP" scheme="https://n4a.github.io/tags/MLP/"/>
    
      <category term="CNN" scheme="https://n4a.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>ml_basic_classifiers</title>
    <link href="https://n4a.github.io/2018/11/17/ml-basic-classifiers/"/>
    <id>https://n4a.github.io/2018/11/17/ml-basic-classifiers/</id>
    <published>2018-11-17T05:26:02.000Z</published>
    <updated>2019-09-17T07:24:24.449Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Task-description"><a href="#1-Task-description" class="headerlink" title="1 Task description"></a>1 Task description</h2><ul><li>Based on the MNIST dataset, design and implement a proper convolutional neural network.</li><li>Based on the MNIST dataset, design and implement classifiers including: least squares with regularization, Fisher discriminant analysis (with kernels), Perceptron (with kernels), logistic regression, SVM (with kernels), MLP-NN with two different error functions.</li><li>(optional)Based on CNN classifiers, please implement an object detection task (including face recognition).</li><li>Design and implement a proper recurrent neural network based on LSTM or/and GRU for Sentiment Analysis. Data is available at <a href="http://deeplearning.net/tutorial/lstm.html" target="_blank" rel="noopener">http://deeplearning.net/tutorial/lstm.html</a></li></ul><a id="more"></a><iframe src="/html/assignment3.html" width="800" height="1000"> Your browser does not support iframe</iframe>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-Task-description&quot;&gt;&lt;a href=&quot;#1-Task-description&quot; class=&quot;headerlink&quot; title=&quot;1 Task description&quot;&gt;&lt;/a&gt;1 Task description&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Based on the MNIST dataset, design and implement a proper convolutional neural network.&lt;/li&gt;
&lt;li&gt;Based on the MNIST dataset, design and implement classifiers including: least squares with regularization, Fisher discriminant analysis (with kernels), Perceptron (with kernels), logistic regression, SVM (with kernels), MLP-NN with two different error functions.&lt;/li&gt;
&lt;li&gt;(optional)Based on CNN classifiers, please implement an object detection task (including face recognition).&lt;/li&gt;
&lt;li&gt;Design and implement a proper recurrent neural network based on LSTM or/and GRU for Sentiment Analysis. Data is available at &lt;a href=&quot;http://deeplearning.net/tutorial/lstm.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://deeplearning.net/tutorial/lstm.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://n4a.github.io/tags/Machine-Learning/"/>
    
      <category term="Classifiers" scheme="https://n4a.github.io/tags/Classifiers/"/>
    
  </entry>
  
  <entry>
    <title>ml basic knowledge practice_regression problem</title>
    <link href="https://n4a.github.io/2018/10/27/ml-basic-knowledge-practice-regression-problem/"/>
    <id>https://n4a.github.io/2018/10/27/ml-basic-knowledge-practice-regression-problem/</id>
    <published>2018-10-27T12:36:48.000Z</published>
    <updated>2018-10-27T12:43:42.586Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Task-Description"><a href="#1-Task-Description" class="headerlink" title="1 Task Description"></a>1 Task Description</h2><p>Use the following dataset to do house price predicting work.</p><ol><li><a href="https://www.kaggle.com/vikrishnan/boston-house-prices" target="_blank" rel="noopener">https://www.kaggle.com/vikrishnan/boston-house-prices</a></li><li><a href="https://github.com/datasets/house-prices-uk" target="_blank" rel="noopener">https://github.com/datasets/house-prices-uk</a></li></ol><p>Details: design a model to do house price predicting work. Linear Regression models including basic linear model based on polynomial, Ridge Regression, Lasso Regression and regression model based Decision Tree must be implemented. Regression models based on SVM and Deep Learning is optional.</p><a id="more"></a><div class="row">    <embed src="/pdf/regression.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-Task-Description&quot;&gt;&lt;a href=&quot;#1-Task-Description&quot; class=&quot;headerlink&quot; title=&quot;1 Task Description&quot;&gt;&lt;/a&gt;1 Task Description&lt;/h2&gt;&lt;p&gt;Use the following dataset to do house price predicting work.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/vikrishnan/boston-house-prices&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.kaggle.com/vikrishnan/boston-house-prices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/datasets/house-prices-uk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/datasets/house-prices-uk&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Details: design a model to do house price predicting work. Linear Regression models including basic linear model based on polynomial, Ridge Regression, Lasso Regression and regression model based Decision Tree must be implemented. Regression models based on SVM and Deep Learning is optional.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mechine Learning" scheme="https://n4a.github.io/tags/Mechine-Learning/"/>
    
      <category term="Regression Probelm" scheme="https://n4a.github.io/tags/Regression-Probelm/"/>
    
  </entry>
  
  <entry>
    <title>To the Moon_拐骗少女的小混混</title>
    <link href="https://n4a.github.io/2018/09/27/%E6%8B%90%E9%AA%97%E5%B0%91%E5%A5%B3%E7%9A%84%E5%B0%8F%E6%B7%B7%E6%B7%B7/"/>
    <id>https://n4a.github.io/2018/09/27/拐骗少女的小混混/</id>
    <published>2018-09-27T01:36:10.000Z</published>
    <updated>2018-09-28T16:58:59.021Z</updated>
    
    <content type="html"><![CDATA[<p>​    这篇文章是在之前的一篇文章的基础上续写的。没有读过的读者可以看一下这篇之前的介绍文。<a href="https://www.bilibili.com/read/cv1128664" target="_blank" rel="noopener">To the Moon 游戏设定介绍</a></p><p>​    To the Moon 这款游戏的剧情设计非常精彩。在游戏中，我们会一点点回溯主人公 John 的记忆。随着对故事的一点一点地深入了解，我们会困惑，会误解，会略带嘲弄，也会略有所感。可是当我们最后看清故事始末，只剩下感动与泪水。</p><p>​    如果想要完整的体验游戏所展现的故事，可以观看下面的视频。</p><iframe src="//player.bilibili.com/player.html?aid=31555731&cid=55173221&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="500"> </iframe><a id="more"></a><iframe src="//player.bilibili.com/player.html?aid=31555731&cid=55173303&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="500"> </iframe><iframe src="//player.bilibili.com/player.html?aid=31555731&cid=55172705&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="500"> </iframe><iframe src="//player.bilibili.com/player.html?aid=31555731&cid=55173120&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="500"> </iframe><p>​    在回溯 John 记忆地过程中，我们发现女主 River 是个奇怪的人，她是一种特殊疾病患者，身患这种疾病的人既希望交流又不回避交流或者有交流障碍，可以理解为交流障碍患者。John 与其交往总是产生各种各样难以交流的问题。但是难能可贵，John 总是包容 River 奇怪的想法，并且想尽一切办法想要治好 River 的病，让她能够过上正常人的生活。这时候我们就会认为这个游戏讲了一个因爱而包容的故事，John 的形象非常饱满正面，值得学习。</p><p>​    但是，当我们来到男主中学时代的时候，就会惊讶的发现男主当年表白的动机并不单纯。Dr. Watts 看到这里之后，感概：“这么说这个家伙是个拐骗少女的小混混？”。</p><p><img src="http://i0.hdslb.com/bfs/article/941c7067c974c99290346fee00135bbf59ae4993.png" alt="img"></p><p>​    John 当初表白的动机和理由都很没有说服力，让他的朋友觉得这简直就是一段时间的骚扰罢了。John 认为 River 是一个特别的人，她总是一个人，那么跟她在一起一定是一件很酷的事。确实这个理由不怎么像是有责任心的人说的话，听上去 John 只是一时兴起，并且这样做可以让他觉得很酷。但是这时候，加上我们前面对 John 和 River 后来发展的了解。这个故事就变成了这样。虽然 John 的动机狗血，却在后来在交往过程中爱上了 River，并且毫不在乎 River 的病症给她带来的困扰。甚至许多年之后，John 认为自己不该对 River 有任何隐瞒，于是他就将自己当年表的动机告诉了 River。自此之后，River 开始以她一贯的特异的表达方式来表达她的感情。她剪了头发，并且开始疯狂地折纸兔子。这里我们机智的 Dr. Watts 又发表了个人感想：“ 然后她就发狂了，并开始做那些诡异的兔子，是吗？”。这确实像一个交流障碍症患者。</p><p><img src="http://i0.hdslb.com/bfs/article/2fa2d54e7f4aadca202379e860630644b6c3239c.png" alt="img"></p><p>​    现在，我们对 John 有了更深入的了解。John 的形象跌了一点，可也还不错。当他后来在交往过程中爱上了 River 之后，无怨无悔地为 River 付出。他对 River 的作为并不能理解，可面对 River 的坚持，他依然照办。至于 River，她的幸福此时也有了一点点不幸。</p><p>​    之后，我们再继续回溯 John 的记忆，发现 John 之前的记忆呈现黑暗和紊乱的状态。这种情况导致我们无法再继续探索。 Dr. Watts 和 Dr. Rosalence 只好基于现有的信息诱导修改 John 的记忆，帮他成去月球的愿望。如果对这个修改记忆的操作不理解可以参考这篇文章<a href="https://www.bilibili.com/read/cv1128664" target="_blank" rel="noopener">To the Moon 游戏设定介绍</a>。然而无论怎么诱导修改，John 之后的记忆演变都没有发生任何改变。最后，Dr. Rosalence 分析是因为我们还不了解 John 为什么想要到月球上去，这使得我们的诱导修改都没有对症下药。面对这种困境，Dr. Watts 和 Dr. Rosalence 想尽了办法终于回溯到了 John 的童年时期。</p><p>接下来就是游戏的高潮部分，所有的感动和泪水也都献给了这个部分。当我们回到 John 童年的时候，发现John 还有一个弟弟 Joey，这一点前面的故事也有很多伏笔。可不幸的是弟弟在院子里玩的时候，妈妈开车时没注意撞到了他。随着弟弟去世，妈妈精神有点失常，并且她给 John 服用了一些消除记忆的药物，好让他忘了这个悲惨的事情。这一切导致 John 的童年记忆难以到达。 在药物的作用下，John 忘记了许多东西，可那个重要的相遇和约定一直存在于 John 脑海的深层之处，只是受药物阻碍无法完整浮现出来。</p><p>随着记忆继续向前回溯，一次邂逅在我们面前展开。这是一个游乐园的场景，John 不想和妈妈、弟弟一起玩，就自己一个人在游乐园寻找有趣的地方，他找到了游乐园山上的一个平常没人去的角落。John在这里欣赏天上的星星。就在这时候，有一个小女孩也来到了这个地方。他们在非常惊讶，同时也很开心有一个人像自己一样来到了这个角落。小女孩的名字叫 River。也就是这一天，John 和 River 第一次相遇。John 是普通的 John，世界上有一大票人都叫 John；River 是特殊的 River，世界上没有几个人叫 River。普通的 John 和 特殊的 River 都喜欢这个角落，在这里他们一起看天上的星星，星星闪闪发光，星星就如同灯塔，向远方的灯塔传达交流的信息。无论是普通的 John 和 特殊的 River，他们一直以来只是以不同的形式保持孤独，但是，此时此刻他们都交到了朋友。</p><p><img src="http://i0.hdslb.com/bfs/article/603476bb36c2a11a7231c698a6e85316a9a6f5fc.png" alt="img"></p><p>​    他们发现了自定义的星座，一个兔子星座，而月亮就是这个兔子圆鼓鼓的肚子。</p><p><img src="http://i0.hdslb.com/bfs/article/f007c801ff21259e0d758da96f185d6850aeee17.png" alt="img"></p><p>​    在分别的时候，他们约定之后再见。“但是如果你忘记了或者走丢了呢？”，“那么我们一定会在月亮上相遇的，傻瓜！”</p><p><img src="http://i0.hdslb.com/bfs/article/330e4365f6d6d442905eee612cb189310cf417dc.png" alt="img"></p><p>​    发展至此，我们了解了故事的始末。一次简单的相遇，却是一生的缘分。再回首过往，所有的谜题都被解开。</p><p>​    John 之所以想去月球，是因为他们曾做了这样的约定，可惜 John 因为药物的影响，对这件事印象模糊了，可他记住了这个约定。“但是如果你忘记了或者走丢了呢？”，“那么我们一定会在月亮上相遇的，傻瓜！”。年老之后，River 因病先他而去。River不在身边之后，这个愿望自发地又浮现在脑海。</p><p>​    John 到中学之后，遇到了一个女孩，他爱上了这个女孩，却不知道为什么。然而他只是忘记了，就好像年老之时他想要去月球，却不知道为什么，现在他爱上了一个女孩，也不知道为什么。潜藏在记忆深处的东西自发地推动着他，让他爱上了这个女孩。“我不知道为什么爱上你，但是我一直有一种感觉：我爱你。” 看似狗血的表白理由，只是因为外人无法了解其内心的感受。</p><p>​    River 也不是若有若无的配角存在，她也不是稀里糊涂地接受了 John 的邀请，她一直在等，在等，等了许多年。感情之事，当局者清，旁观者迷。</p><p>​    John 之后一直深爱着 River，尝试所有办法来治好 River。可惜这个可怜的失忆的人不曾意识到自己的问题。“我倾尽一生想要治好你，却没有发现病人原来是自己”。</p><p>​    特殊的 River 更是一直深爱着 John，以她独特的方式。当 John 向她抛白中学时代的愧疚之后。River 剪了头发，因为他们第一次相见的时候，她是短发；她不断的折着纸兔子，因为那是他们的兔子星座；她宁愿放弃自己的治疗，也要在那个废弃的灯塔旁边盖起他们自己的房子，因为那灯塔就是他们相遇时的天上的星星。她所作的一切怪异的事情只是为了唤起 John 的记忆。</p><p>​    命运为幸福的人带来不幸，不幸的人却幸福地活着。</p><p>​    浅薄的言语永远无法表达游戏带来的感受，我推荐这款游戏，希望将这份感动送给你。<a href="https://www.bilibili.com/video/av31555731/?p=1" target="_blank" rel="noopener">To the Moon 游玩记录</a></p><p>​    游戏至此依然没有结束，之后的故事之后再说吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​    这篇文章是在之前的一篇文章的基础上续写的。没有读过的读者可以看一下这篇之前的介绍文。&lt;a href=&quot;https://www.bilibili.com/read/cv1128664&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;To the Moon 游戏设定介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​    To the Moon 这款游戏的剧情设计非常精彩。在游戏中，我们会一点点回溯主人公 John 的记忆。随着对故事的一点一点地深入了解，我们会困惑，会误解，会略带嘲弄，也会略有所感。可是当我们最后看清故事始末，只剩下感动与泪水。&lt;/p&gt;
&lt;p&gt;​    如果想要完整的体验游戏所展现的故事，可以观看下面的视频。&lt;/p&gt;
&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=31555731&amp;cid=55173221&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot; width=&quot;100%&quot; height=&quot;500&quot;&gt; &lt;/iframe&gt;
    
    </summary>
    
    
      <category term="个人" scheme="https://n4a.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
      <category term="生活" scheme="https://n4a.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="To the Moon" scheme="https://n4a.github.io/tags/To-the-Moon/"/>
    
  </entry>
  
</feed>
