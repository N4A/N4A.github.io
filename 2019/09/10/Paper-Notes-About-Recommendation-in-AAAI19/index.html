<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Recommender Systems,Knowledge graph,RNN,Attention Mechanism," />





  <link rel="alternate" href="/atom.xml" title="N4A Space" type="application/atom+xml" />






<meta name="description" content="Overview">
<meta name="keywords" content="Recommender Systems,Knowledge graph,RNN,Attention Mechanism">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper_Notes_About_Recommendation_in_AAAI19">
<meta property="og:url" content="https://n4a.github.io/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/index.html">
<meta property="og:site_name" content="N4A Space">
<meta property="og:description" content="Overview">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/overview.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/session-graph.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/camo.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/kg-lstm.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/reward-hacking.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/meta-loss-vs-aggregation.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hierarchical-interests.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/multi-view-learning.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/multi-view-learning-exp.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/dynamic-gru.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/dynamic-explanation-demo.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/news-rec.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/repeat-ratio.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/repeatnet.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/sequential-interest.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hcrnn-lstm.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hcrnn-1.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hcrnn-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hcrnn-embedding.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/poi-intervals.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/poi-lstm.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/poi-gates.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/union-relevance.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/union-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/drug-loss.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/drug-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/cross-domain-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/binary-vector.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/dsr-exp1.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/dsr-exp2.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/deep-cf.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/tag-demo.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/tag-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/photo-tag-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hfm-fm.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hfm.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/hfm-convolution.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/influence-fuzzing.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/trans-framework.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/trans-mmtg.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/trans-loss.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/course-intuition.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/course-data.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/course-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/nc-framework.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/context-intuition.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/context-arch.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/context-score.PNG">
<meta property="og:image" content="https://n4a.github.io/img/aaai19/irs-tree.PNG">
<meta property="og:updated_time" content="2019-09-24T08:10:25.016Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Paper_Notes_About_Recommendation_in_AAAI19">
<meta name="twitter:description" content="Overview">
<meta name="twitter:image" content="https://n4a.github.io/img/aaai19/overview.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://n4a.github.io/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/"/>





  <title>Paper_Notes_About_Recommendation_in_AAAI19 | N4A Space</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">N4A Space</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">To understand and be understood</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://n4a.github.io/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="N4A">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="N4A Space">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Paper_Notes_About_Recommendation_in_AAAI19</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-10T15:53:58+08:00">
                2019-09-10
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/09/10/Paper-Notes-About-Recommendation-in-AAAI19/" class="leancloud_visitors" data-flag-title="Paper_Notes_About_Recommendation_in_AAAI19">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p><img src="/img/aaai19/overview.PNG" alt=""></p>
<a id="more"></a>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Explainability"><a href="#Explainability" class="headerlink" title="Explainability"></a>Explainability</h2><p>Recently, the recommendation community has reached a consensus that accuracy can only be used to partially evaluate a system. Explainability of the model, which is the ability to provide explanations for why an item is recommended, is considered equally important.</p>
<p>Papers like follows:</p>
<ol>
<li><a href="#explainable-reasoning-over-knowledge-graphs-for-recommendation">Explainable Reasoning over Knowledge Graphs for Recommendation</a>: Use knowledge graph(KG) info for explainability. Select the most related path in KG as the explanation.</li>
<li><a href="#Explainable Recommendation Through Attentive Multi-View Learning">Explainable Recommendation Through Attentive Multi-View Learning</a>: Construct a hierarchical (explicit) feature (e.g. meat, seafood and so on) tree for explainability. Select the most related features as explanation.</li>
<li><a href="#Dynamic Explainable Recommendation based on Neural Attentive Models">Dynamic Explainable Recommendation based on Neural Attentive Models</a>: Generate dynamic explanations at different time for a user by using GRU. An explanation is the most related sentence in the review of the recommended item.</li>
</ol>
<h2 id="Sequential-Recommendation"><a href="#Sequential-Recommendation" class="headerlink" title="Sequential Recommendation"></a>Sequential Recommendation</h2><p>Different from traditional MF that treats users and items equally, the methods model the interactions between users and items as a number of historical interaction sequences of users.  Then focusing on the sequential interactions of users, some methods was proposed to analysis the phenomenon like long-term interests, drifted interests, repeat consumption and some other task-specific aspects. The tasks include next item (basket) prediction (like POI), session recommendation. </p>
<ol>
<li><a href="#A Repeat Aware Neural Recommendation Machine for Session-based Recommendation">A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</a>: Emphasize the importance of repeat consumption.</li>
<li><a href="#Session-based Recommendation with Graph Neural Networks">Session-based Recommendation with Graph Neural Networks</a>: Model item transitions in sessions as a Graph.</li>
<li><a href="#Hierarchical Context enabled Recurrent Neural Network for Recommendation">Hierarchical Context enabled Recurrent Neural Network for Recommendation</a>: Emphasize global long-term interests, local sub-sequence interests and the temporary interests of each transition in a sequence.</li>
<li><a href="#A Spatio-Temporal Gated Network for Next POI Recommendation">A Spatio-Temporal Gated Network for Next POI Recommendation</a>: Emphasize the influence of spatio-temporal intervals between check-ins for POI recommendation.</li>
<li><a href="#Multi-order Attentive Ranking Model for Sequential Recommendation">Multi-order Attentive Ranking Model for Sequential Recommendation</a>: Emphasize the difference of individual-level and union level item relevance.</li>
</ol>
<h2 id="Cross-Domain-Recommendation"><a href="#Cross-Domain-Recommendation" class="headerlink" title="Cross Domain Recommendation"></a>Cross Domain Recommendation</h2><ol>
<li><a href="#Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems">Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems</a>: User more kinds of auxiliary info.</li>
<li><a href="#From Zero-Shot Learning to Cold-Start Recommendation">From Zero-Shot Learning to Cold-Start Recommendation</a>: Use ZSL method to solve CSR problem</li>
</ol>
<h2 id="Improve-Basic-Methods"><a href="#Improve-Basic-Methods" class="headerlink" title="Improve Basic Methods"></a>Improve Basic Methods</h2><ol>
<li><a href="#Holographic Factorization Machines for Recommendation">Holographic Factorization Machines for Recommendation</a>: Improve Factorization Machine (FM) with convolution operation.</li>
<li><a href="#Non-Compensatory Psychological Models for Recommender Systems">Non-Compensatory Psychological Models for Recommender Systems</a>: A novel method following the non-compensatory rules in consumer psychology while all traditional latent factor models fall into category of compensatory rules.</li>
<li><a href="#Discrete Social Recommendation">Discrete Social Recommendation</a>: To speedup models with quantization while maintain the performance as possible as we can.</li>
<li><a href="#A Unified Framework of Representation Learning and Matching Function Learning in Recommender System">A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</a>: A combination of two kinds conventional methods: representation learning based methods like MF and matching function learning based methods like NCF.</li>
</ol>
<h2 id="Specific-Tasks"><a href="#Specific-Tasks" class="headerlink" title="Specific Tasks"></a>Specific Tasks</h2><p>These methods utilize the information in some specific scenarios.</p>
<ol>
<li>POI recommendation as above</li>
<li><a href="#DAN: Deep Attention Neural Network for News Recommendation">DAN: Deep Attention Neural Network for News Recommendation</a>: Do a specific task with a complex combination of popular networks (actually news is just treated as text). The emphasized point is still the order info that has been studied for general recommendation over and over again.</li>
<li><a href="#Graph Augmented MEmory Networks for Recommending Medication Combination">Graph Augmented MEmory Networks for Recommending Medication Combination</a>: Also a specific task that recommends medication combination. The point is to process patient health history and drug-drug interactions with proper techniques. </li>
<li><a href="#An Integral Tag Recommendation Model for Textual Content">An Integral Tag Recommendation Model for Textual Content</a>: The authors emphasize three aspects of tag recommendation that impact the accuracy: 1) sequential text modeling. 2) tag correlation. 3) content-tag overlapping.</li>
<li><a href="#Hashtag Recommendation for Photo Sharing Services">Hashtag Recommendation for Photo Sharing Services</a>: Utilize info of image, text and personalized habits.</li>
<li><a href="#Joint Representation Learning for Multi-Modal Transportation Recommendation">Joint Representation Learning for Multi-Modal Transportation Recommendation</a>: Multi-Modal Transportation Recommendation. The main contribution is to format this problem while the method is simple.</li>
<li><a href="#Hierarchical Reinforcement Learning for Course Recommendation in MOOCs">Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</a>: Use RL to revise user profiles by removing the noisy courses instead of assigning an attention weight to each of them. The basic idea is independent from MOOCs but the author use info only in MOOCs to present state in RL.</li>
</ol>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ol>
<li><a href="#A Collaborative Ranking Method for Content Based Recommendation">A Collaborative Ranking Method for Content Based Recommendation</a>: Follow a traditional line that generates item embedding from auxiliary info and then combine it with MF like $u_i^T(v_j + embedding(doc_j))$</li>
<li><a href="#Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation">Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation</a>: A general formation of recommendation with user-item interaction, user-user relation(social relation), item-item relation.</li>
<li><a href="#Evaluating Recommender System Stability with Influence-Guided Fuzzing">Evaluating Recommender System Stability with Influence-Guided Fuzzing</a>: Predefine some modifications to modify the dataset and then evaluate the stability of some classical recommendation method.</li>
<li><a href="#Large-scale Interactive Recommendation with Tree-structured Policy Gradient">Large-scale Interactive Recommendation with Tree-structured Policy Gradient</a>: Construct all items as tree to reduce the time complexity of choosing an item from all items.</li>
<li><a href="#Meta Learning for Image Captioning">Meta Learning for Image Captioning</a></li>
<li>From Recommendation Systems to Facility Location Games: An interest aspect for recommendation problem. The authors design a Mediator (for service providers) to direct what the content providers(e.g. blog/video publishers) should provide to achieve overall higher social welfare while intervene as little as possible. The introduction of method is omitted for it is more related to social science and a bit complex.</li>
<li>Multi-Level Deep Cascade Trees for Conversion Rate Prediction in Recommendation: A problem related to recommendation. The problem want to predict conversion rate when users have clicked and viewed recommended items. Briefly, take Taobao for an example, conversion means users bought the recommended item after they clicked and viewed the item.</li>
</ol>
<h1 id="Session-based-Recommendation-with-Graph-Neural-Networks"><a href="#Session-based-Recommendation-with-Graph-Neural-Networks" class="headerlink" title="Session-based Recommendation with Graph Neural Networks"></a>Session-based Recommendation with Graph Neural Networks</h1><p>Problem: Session Recommendation</p>
<p>Gap: Transitions among distant items are often overlooked by previous methods. </p>
<p>Method: Use Graph to model item relation in sessions and utilize Graph Neural Networks to capturing transitions of items and generate accurate item embedding vectors. For example, as follows, the three sessions are constructed as a graph.</p>
<p><img src="/img/aaai19/session-graph.PNG" alt="Session graph"></p>
<h1 id="A-Collaborative-Ranking-Method-for-Content-Based-Recommendation"><a href="#A-Collaborative-Ranking-Method-for-Content-Based-Recommendation" class="headerlink" title="A Collaborative Ranking Method for Content Based Recommendation"></a>A Collaborative Ranking Method for Content Based Recommendation</h1><p>Problem: A traditional line that uses auxiliary information to enrich item embedding based on MF. The general score function for user $i$, item $j$ and auxiliary info $doc_j$ is as followings:<br>$$<br>f(i,j,doc_j) = p_i^T(q_j + g(doc_j))<br>$$<br>where $g(.)$ is the encoding function.</p>
<p>Gap: For function $g(.)$, some methods ignore the order of words, while others fail to identify the high leveled topic info.</p>
<p>Method: An encoding function based on GRU(capture order) and multi-head attention mechanism(model topic info).</p>
<p><img src="/img/aaai19/camo.PNG" alt="CAMO"></p>
<p>A Nice Attention Introduction: <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a></p>
<h1 id="Explainable-Reasoning-over-Knowledge-Graphs-for-Recommendation"><a href="#Explainable-Reasoning-over-Knowledge-Graphs-for-Recommendation" class="headerlink" title="Explainable Reasoning over Knowledge Graphs for Recommendation"></a>Explainable Reasoning over Knowledge Graphs for Recommendation</h1><p>Problem: recommendation with explainability, using KG specifically.</p>
<p>Gap: The connectivity information in KG can help to endow recommender systems the ability of reasoning and explainability. However, some traditional methods(use meta-paths) need domain knowledge to predefine meta-paths, while others(embedding based, like using TransE) are less explainable.</p>
<p>Method:</p>
<ol>
<li><p>Model user-item interaction $(u, i)$ as KG triplet relation $(u, interact, i)$.</p>
</li>
<li><p>For each $(u,i)$, select all paths from user node $u$ to item node $i$, denoted as $P(u,i) = {p_1, p_2, …, p_K}$</p>
</li>
<li><p>The score function from user $u$ to item $i$ is modeled as:<br>$$<br>\hat{y}<em>{ui} = f</em>{\Theta}(u,i|P(u,i))<br>$$</p>
</li>
<li><p>Use LSTM to model the preference of each path and use a weighted pooling layer(not attention) to calculate the final preference and estimate the importance of each path.</p>
<p><img src="/img/aaai19/kg-lstm.PNG" alt="kg-lstm"></p>
</li>
</ol>
<p>Weighted Pooling Layer:</p>
<p>For each preference $s_k$ outputted from the LSTM layer, the weighted pooling layer is defined as follows:<br>$$<br>g(s_1, s_2, …, s_K) = log[\sum_{k=1}^K \exp (\frac{s_K}{\gamma})]<br>$$<br>where $\gamma$ is a hyper-parameter to control each exponential weight and the path importance is estimated from the gradient on each path preference:<br>$$<br>\frac{\partial g}{\partial s_k} = \frac{\exp (s_k/ \gamma)}{\gamma \sum_{k^{‘}} \exp (s_{k^{‘}}/\gamma)}<br>$$<br>Finally,  the score function is<br>$$<br>y_{ui} = \sigma(g(s_1,s_2,…,s_K))<br>$$</p>
<h1 id="From-Zero-Shot-Learning-to-Cold-Start-Recommendation"><a href="#From-Zero-Shot-Learning-to-Cold-Start-Recommendation" class="headerlink" title="From Zero-Shot Learning to Cold-Start Recommendation"></a>From Zero-Shot Learning to Cold-Start Recommendation</h1><p>Problem: Cold-start Recommendation(CSR)</p>
<p>Gap: no gap but a novel view in light of Zero-Shot Learning(ZCL). Actually, I am not used to this kind of writing pattern.</p>
<p>Challenge to formulate CSR as a ZSL problem: </p>
<ol>
<li>Domain shift problem: the data distribution is not same as in ZSL</li>
<li>Data sparsity: the interactions in recommendation domain is very sparse.</li>
<li>Efficiency. </li>
</ol>
<p>Method: Use a Linear Low-rank Autoencoder to learn a transform matrix $W$ that transfer user behavior matrix $X$ into user attributes matrix $S$ as follows:<br>$$<br>\min_{W}|| X - W^TWX||<em>F^2 + \beta rank(W),  s.t. WX = S<br>$$<br>Then, for new users, we can estimate their potential user behavior matrix $X</em>{new}$ as<br>$$<br>X_{new} = W^TS_{new}<br>$$<br>My concern is how the autoencoder or low-rank constraint solve the data sparsity problem in Recommendation domain. In ZSL, each $X$ is an image with enough info. However, in RS, each $X$ is an interaction matrix which is very sparse and in total, there is only one large matrix with the user number as row number and item number as column number as train data. Compare to ZSL, the train dataset is also very small.</p>
<p>A similar low-rank Autoencoder for ZSL in IJCAI’18: <a href="https://www.ijcai.org/proceedings/2018/0345.pdf" target="_blank" rel="noopener">Zero Shot Learning via Low-rank Embedded Semantic AutoEncoder</a></p>
<h1 id="Meta-Learning-for-Image-Captioning"><a href="#Meta-Learning-for-Image-Captioning" class="headerlink" title="Meta Learning for Image Captioning"></a>Meta Learning for Image Captioning</h1><p>Problem: Image caption</p>
<p>Gap: reward hacking problem in RL. Shown in the following figure, the reward (digit next to the caption) of caption generated by RL is even higher than the ground truth (GT) caption while the caption quality is actually not.</p>
<p><img src="/img/aaai19/reward-hacking.PNG" alt="Reward hacking in image caption"></p>
<p>Method: Utilize the power of meta-learning to ensure the correctness and distinctiveness of the generated captions(by RL reward) and optimize the evaluation metrics(by maximizing the likelihood of the ground truth caption). Shown in the following graph, the meta-learning objective(marked in green) could the learn $\theta$ that is optimal to adapt both tasks while just adding RL reward $L_1(\theta)$ with maximize likelihood target $L_2(\theta)$takes a gradient in between (marked in brown).</p>
<p><img src="/img/aaai19/meta-loss-vs-aggregation.PNG" alt="meta loss vs aggregation"></p>
<p>The idea behind this work may suggest that we should use meta-learning optimization method to substitute trivial aggregation of different losses in all kinds of works if there is the similar hacking problem in the corresponding domains.</p>
<h1 id="Explainable-Recommendation-Through-Attentive-Multi-View-Learning"><a href="#Explainable-Recommendation-Through-Attentive-Multi-View-Learning" class="headerlink" title="Explainable Recommendation Through Attentive Multi-View Learning"></a>Explainable Recommendation Through Attentive Multi-View Learning</h1><p>Problem: recommendation with explainability</p>
<p>Gap: On one hand, some deep learning-based methods lack of explainability. On other hand, other shallow models lack of an effective mechanism to model high-level explicit features which limits their accuracy. What’s more they can’t identify hierarchical interests. As shown in the following graph, previous works can not identify whether a user is interested in lower-level features such as $\textit{shrimp}$ or higher-level features like $\textit{seafood}$.</p>
<p><img src="/img/aaai19/hierarchical-interests.PNG" alt="hierarchical interests"></p>
<p>Method: feed the model with the hierarchical features information. An overview is as follows.</p>
<ol>
<li>Build an explicit feature hierarchy $\gamma$ with in total $L$ features and $H$ layers from the collected data like <a href="https://concept.research.microsoft.com/" target="_blank" rel="noopener">Microsoft Concept Graph</a>. Pretrain with the graph to get the embedding $e_i$ of each feature node.</li>
<li>For a user $i$,  collect his explicit user-feature interest $x_i$ from his reviews. $x_{il}$ indicates the frequence of the feature $F_l$ being mentioned by the user.</li>
<li>propagate the feature-interest on the tree to get more proper interest $\hat{x_i}$ to let each interest on the feature node contain the interests on its sub-nodes. </li>
<li>For items, build their features denoted as $\hat{y_j}$ from product introduction in a similar way. </li>
<li>Attentive multi-view learning with the ratings and collected features as supervising info. Each user and item has an implicit feature and an explicit feature. Both features need fit ratings based on MF while the explicit features need also  fit collected features with a linear transform and L2 loss.</li>
</ol>
<p>The overall process is as follows.</p>
<p><img src="/img/aaai19/multi-view-learning.PNG" alt=""></p>
<p>Then for explainability, the method utilize the feature hierarchy $\gamma$ and the trained model to select some important features as reason of recommendation.</p>
<p>Additionally, from the experimental results shown in the following figure, we can see SVD++ performs well with RMSE metric and even performs better than some deep models likes DeepCoNN and NARRE that using review info. The phenomenon should be discussed more detailly.</p>
<p><img src="/img/aaai19/multi-view-learning-exp.PNG" alt=""></p>
<h1 id="Dynamic-Explainable-Recommendation-based-on-Neural-Attentive-Models"><a href="#Dynamic-Explainable-Recommendation-based-on-Neural-Attentive-Models" class="headerlink" title="Dynamic Explainable Recommendation based on Neural Attentive Models"></a>Dynamic Explainable Recommendation based on Neural Attentive Models</h1><p>Problem: recommendation with explainability</p>
<p>Gap: Most previous works represent a user as a static latent vector($most$ is a good word). More importantly, <em>the explanations provided by these models are usually invariant</em>.</p>
<p>Method: Use GRU to model dynamic interest of users. Add a time gate to GRU to use the message of time interval. For example, a user tend to have similar preferences within a short time, while large time gap may have more opportunities to change user interest. For an item, use the hidden state $h_s$ of GRU at current time as the user’s interest to select the most related sentence in the reviews as explanation by making use of attention mechanism. The general process is shown in following figure.</p>
<p><img src="/img/aaai19/dynamic-gru.PNG" alt=""></p>
<p>An example of explanation is shown as follows.</p>
<p><img src="/img/aaai19/dynamic-explanation-demo.PNG" alt=""></p>
<h1 id="DAN-Deep-Attention-Neural-Network-for-News-Recommendation"><a href="#DAN-Deep-Attention-Neural-Network-for-News-Recommendation" class="headerlink" title="DAN: Deep Attention Neural Network for News Recommendation"></a>DAN: Deep Attention Neural Network for News Recommendation</h1><p>Problem: News recommendation (next item recommendation)</p>
<p>Gap: They usually fail with the dynamic diversity of news and user’s interests, or ignore the importance of sequential information of user’s clicking selection. (This is obviously a false assertion for general recommendation) </p>
<p>Method: Combination of CNN, RNN and Attention Mechanism. </p>
<p><img src="/img/aaai19/news-rec.PNG" alt=""></p>
<p>As shown in the above figure, the process is summary as:</p>
<ol>
<li><p>Use two CNN(PCNN) to extract embedding of news with title and profile parts.</p>
</li>
<li><p>Use LSTM and Attention to learn a user’s embedding with a sequence of clicked news.</p>
</li>
<li><p>Score function is based on similarity between user embedding and candidate news embedding as follows. The $cosine$ function is calculated by the inner product of two vectors which is the same with MF but with different name.<br>$$<br>P = cosine(\hat{I}_t . I_t)<br>$$</p>
</li>
</ol>
<h1 id="A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation"><a href="#A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation" class="headerlink" title="A Repeat Aware Neural Recommendation Machine for Session-based Recommendation"></a>A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</h1><p>Problem: session recommendation</p>
<p>Gap: propose a novel <em>repeat consumption</em> phenomenon where the same item is re-consumed repeatedly over time. The following table shows the repeat ratio in three public datasets.  However, no previous works have emphasized <em>repeat consumption</em> with neural networks. (Multi-armed bandit problem has been studied for a long time to solve the repeat-explore dilemma for general recommendations.)</p>
<p><img src="/img/aaai19/repeat-ratio.PNG" alt=""></p>
<p>Method: </p>
<p><img src="/img/aaai19/repeatnet.PNG" alt=""></p>
<p>As shown in the above figure, the process is summarized as:</p>
<ol>
<li>Use GRU to encode the session sequence of a user.</li>
<li>Use attention mechanism to merge all hidden states with the last hidden state as attention point. Then use a dense network to transform the merged vector into a two dimension vector with the first value as the probability of <em>repeat</em> and the other as the probability of <em>explore</em></li>
<li>For repeat mode, decode the hidden states to calculate score for each item (new items get 0 point)</li>
<li>For explore mode, decode the hidden states with attention to calculate for each item (old items get 0 point)</li>
<li>Use the score and whether the item is new as supervising info to train model with a negative log-likelihood loss and a logistic loss.</li>
</ol>
<h1 id="Hierarchical-Context-enabled-Recurrent-Neural-Network-for-Recommendation"><a href="#Hierarchical-Context-enabled-Recurrent-Neural-Network-for-Recommendation" class="headerlink" title="Hierarchical Context enabled Recurrent Neural Network for Recommendation"></a>Hierarchical Context enabled Recurrent Neural Network for Recommendation</h1><p>Problem: Next-item recommendation</p>
<p>Gap: Emphasize long-term interests, local sub-sequence interests and temporary interests of each transition which are shown in the following graph while all these interests have only been partially reflected in most previous works.</p>
<p><img src="/img/aaai19/sequential-interest.PNG" alt=""></p>
<p>Method: (the authors assume each sequence should be longer than 10 in experiments)</p>
<p>Traditional LSTM process is shown as follows:</p>
<p><img src="/img/aaai19/hcrnn-lstm.PNG" alt=""></p>
<p>The authors propose to use cell state $c_t$ to present the local-sub sequence interests and use hidden state $h_t$ to present temporary transition interests. However, in traditional LSTM, $h_t$ are only directly dependent on $c_t$, there is little difference between them. Besides the long-term interests are neglected if $c_t$ is treated only as local interest. So, the author modify to LSTM to let $h_t$ more independent and add a memory network to keep long-term interests. The process is shown as </p>
<p><img src="/img/aaai19/hcrnn-1.PNG" alt=""></p>
<p>where the parameter $\theta$ are trainable parameter $\theta$ for attention mechanism. Then in each transition, the influence of global long-term interests is considered.</p>
<p>The general process is shown in the following graph in which other tricks like bi-channel attention for prediction to focus on all interests are simply demonstrated.</p>
<p><img src="/img/aaai19/hcrnn-arch.PNG" alt=""></p>
<p>One way to demonstrate global interests is shown in the following graph from which we can see global context vector cover the most of the items.</p>
<p><img src="/img/aaai19/hcrnn-embedding.PNG" alt=""></p>
<h1 id="A-Spatio-Temporal-Gated-Network-for-Next-POI-Recommendation"><a href="#A-Spatio-Temporal-Gated-Network-for-Next-POI-Recommendation" class="headerlink" title="A Spatio-Temporal Gated Network for Next POI Recommendation"></a>A Spatio-Temporal Gated Network for Next POI Recommendation</h1><p>Problem: POI recommendation (next item prediction)</p>
<p>Gap: Most previous recommendation methods don’t consider both time intervals and geographical distances between neighbor items that are shown in bellowing figure. And some other methods may fail to model spatial and temporal relations of neighbor check-ins properly (see paper for more detail discussion).</p>
<p><img src="/img/aaai19/poi-intervals.PNG" alt=""></p>
<p>Method: </p>
<p><img src="/img/aaai19/poi-lstm.PNG" alt=""></p>
<p>Shown in the above figure, based on LSTM, the authors also add two time interval gates and  two distance gates (no direction info) besides the input gate.</p>
<p><img src="/img/aaai19/poi-gates.PNG" alt=""></p>
<p>Gates $T1, D1$ are used to  filter new information considering influence of time interval and distance and then the filtered information is transferred to the hidden state and finally influences the next recommendation. Gates $T2, D2$ are used in a similar way for estimating new cell state.</p>
<h1 id="Multi-order-Attentive-Ranking-Model-for-Sequential-Recommendation"><a href="#Multi-order-Attentive-Ranking-Model-for-Sequential-Recommendation" class="headerlink" title="Multi-order Attentive Ranking Model for Sequential Recommendation"></a>Multi-order Attentive Ranking Model for Sequential Recommendation</h1><p>Problem: Next item recommendation</p>
<p>Gap: Except for the individual-level relevance, union-level item relevance also influence a user’s interactions. For example, buying eggs, milk, and butter together indicates a higher probability of buying flour than eggs, milk or butter individually.  However, most previous works neglected the union-level relevance and others didn’t model it well (see paper for more detail discussion). The following figure shows two kinds of relevance.</p>
<p><img src="/img/aaai19/union-relevance.PNG" alt=""></p>
<p>Method: To predict the score of item $j$ for a user $u$, the authors also directly add the influence of the items, denote as a set $S_{t-1,n}^u$, that the user has interacted with recently. Then the final prediction is estimated as<br>$$<br>\hat{y}_{u,j} = p_uq_j^T + F(u, S_{t-1,n}^u)m_j^T<br>$$<br>Then the point is how to model the union-level preference $F(u, S_{t-1,n}^u)$.</p>
<p><img src="/img/aaai19/union-arch.PNG" alt=""></p>
<p>Generally, shown in the left of the above figure, the authors use the user feature $p_u$ as the attention point to decide the weight of each item $S_{t-1,n}^u$ with as special Multi-order Attention Network (see paper for detail). The the output, denoted as $e_c$, of the Attention Network could regard as the individual-level influence of the items in $S_{t-1,n}^u$ to the target item $j$ with each item with different attention weight. To capture the union-level influence, the authors add a L-layer ResNet to fuse the influence in $e_c$ to a high-level feature, denoted as $h_L$. Finally the feature $F(u, S_{t-1,n}^u)$ is $e_c + h_L$.</p>
<h1 id="Graph-Augmented-MEmory-Networks-for-Recommending-Medication-Combination"><a href="#Graph-Augmented-MEmory-Networks-for-Recommending-Medication-Combination" class="headerlink" title="Graph Augmented MEmory Networks for Recommending Medication Combination"></a>Graph Augmented MEmory Networks for Recommending Medication Combination</h1><p>Problem: Recommend medication combination, a special specific task</p>
<p>Gap: Existing approaches either do not customize based on patient health history, or ignore existing knowledge on drug-drug interactions (DDI) that might lead to adverse outcomes.  </p>
<p>Method: The method is a bit complex in actual. Briefly:</p>
<ol>
<li><p>Use Graph to represent the DDI relation and the estimated drug combination relation from patient health history.</p>
</li>
<li><p>Use GCN (Graph Convolutional Network) to learn Graph node representations and then format them as two memory networks: 1) memory bank (MB): the key and value are both node embeddings. 2) dynamic memory (DM): the key is embedding of  a user’s historical diseases (learned as follows)  before current time and the value the the corresponding medication combination.</p>
</li>
<li><p>Use RNN to learn embeddings of a user’s  historical diseases at each time, denoted as $q_t$.</p>
</li>
<li><p>Use $q_t$ as query vector to query the two memories built as above and use the collected memory to do a multi-label classification to recommend medication combination</p>
</li>
<li><p>Besides the traditional multi-label classification loss, the authors also add a DDI loss to avoid drug-drug -interactions like follows where $A_d[i,j] = 1$ if drug $i$ has an interaction on drug $j$<br>$$<br>L_{DDI} = \sum_t^T \sum_{i,j}(A_d \odot (\hat{y}_t^T\hat{y_t}))[i,j]<br>$$</p>
</li>
<li><p>Additionally, the authors use a special combined loss functions in medication instead of weighted aggregation</p>
<p><img src="/img/aaai19/drug-loss.PNG" alt=""></p>
<p>Finally, the overall architecture is shown in the following figure. A users’ historical disease consists of two parts. One is the diagnoses code $c_d^t$ and the other is the procedure code $c_p^t$ </p>
<p><img src="/img/aaai19/drug-arch.PNG" alt=""></p>
</li>
</ol>
<h1 id="Deeply-Fusing-Reviews-and-Contents-for-Cold-Start-Users-in-Cross-Domain-Recommendation-Systems"><a href="#Deeply-Fusing-Reviews-and-Contents-for-Cold-Start-Users-in-Cross-Domain-Recommendation-Systems" class="headerlink" title="Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems"></a>Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems</h1><p>Problem: Cross-Domain Recommendation for cold-start users.</p>
<p>Gap: Most existing cross-domain recommendation works still do not take full consideration of different kinds of valuable side information (In this paper, there are two kinds of information: review texts and item contents).</p>
<p>Method:</p>
<p><img src="/img/aaai19/cross-domain-arch.PNG" alt=""></p>
<p>The framework is shown as above, the brief process is summarized as:</p>
<ol>
<li>For both domain, the text info of a user is all of his review texts, the text info for a item is all reviews on it. Besides, in auxiliary domain, the text info of item also includes item contents. </li>
<li>Use Stacked Denoising Autoencoders to encoding a user according to his/her ratings on all items with the text info as a side info (like AUR_u in the left bottom). Learn the representations of items in a similar way except for items in auxiliary domain that also utilize item contents (AIP_i(A) in upper center)</li>
<li>Use MF to predict ratings in both domain</li>
<li>Use MLP to transfer the features in auxiliary domain to target domain.</li>
</ol>
<p>My concern is that the MLP part only tunes parameters of MLP based on this transform method. In another word, the features of users and items should be pretrained. Then the pretraining of $U$ and $V$ to let them prepared for the transform part will be a hard work utilizing only the sparse rating matrices. Instead, the pretraining works in other domain like NLP and CV usually need a very large dataset.</p>
<h1 id="Discrete-Social-Recommendation"><a href="#Discrete-Social-Recommendation" class="headerlink" title="Discrete Social Recommendation"></a>Discrete Social Recommendation</h1><p>Problem: social recommendation</p>
<p>Gap: With traditional methods like MF, the large volume of user/item latent features results in expensive storage and computation cost, particularly on terminal user devices where the computation resource to operate model is very limited. Besides, some quantization methods(use lower precision values, e.g. 2-bit int vector instead of 32-bit float vector) would lose accuracy after the model has been trained.</p>
<p>Method: To learn binary vector as features of users and items.</p>
<p><img src="/img/aaai19/binary-vector.PNG" alt=""></p>
<p>Shown in the above figure, the idea is simple. All feature vectors $b_i, d_j, f_k$ are binary vectors. Here $S$ is the social relation between users and $f_k$ is a third latent feature (different from $b_k$).</p>
<p>The challenge is how to optimize this problem. The problem is a little similar with NMF, but this problem has much more constraint conditions. See the original paper for detail optimizing method if you are interested.</p>
<p>The following figures show the performance and time cost. DSR is the proposed model and r is code length.</p>
<p><img src="/img/aaai19/dsr-exp1.PNG" alt=""></p>
<p><img src="/img/aaai19/dsr-exp2.PNG" alt=""></p>
<h1 id="A-Unified-Framework-of-Representation-Learning-and-Matching-Function-Learning-in-Recommender-System"><a href="#A-Unified-Framework-of-Representation-Learning-and-Matching-Function-Learning-in-Recommender-System" class="headerlink" title="A Unified Framework of Representation Learning and Matching Function Learning in Recommender System"></a>A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</h1><p>Problem: Traditional recommendation problem.</p>
<p>Gap: Divide traditional methods into two types. One is representation learning based like MF and the other is matching function learning based like NCF. The authors combine these two kinds of methods.</p>
<p>Method:</p>
<p><img src="/img/aaai19/deep-cf.PNG" alt=""></p>
<p>In my view, the method is under NCF framework. However, different from NCF, the representation of users and items are not randomly initialized but learning by two representation function $f$ and $g$ from raw ratings.</p>
<p>The method is simple. But the difficult point is to train a deep network with sparse ratings in which the model is easy to be overfitting.</p>
<h1 id="An-Integral-Tag-Recommendation-Model-for-Textual-Content"><a href="#An-Integral-Tag-Recommendation-Model-for-Textual-Content" class="headerlink" title="An Integral Tag Recommendation Model for Textual Content"></a>An Integral Tag Recommendation Model for Textual Content</h1><p>Problem: Tag recommendation</p>
<p>Gap:  An example of tags to a text is shown in the following graph. The authors emphasize three aspects of tag recommendation that impact the accuracy: 1) sequential text modeling. This a common aspect. 2) tag correlation. The tags for a text are usually related with each other. 3) content-tag overlapping. Tags are often overlapped with the word in  original text.  However, there lacks an integral method that captures all the three aspects with a coherent model.</p>
<p><img src="/img/aaai19/tag-demo.PNG" alt=""></p>
<p>Method:</p>
<p><img src="/img/aaai19/tag-arch.PNG" alt=""></p>
<p>As shown in the above figure, the authors use an Multi-Layer GRU as an Encoder to encode the original text and another Multi-layer GRU as a Decoder to generate tags.</p>
<ol>
<li><p>GRU could capture the order info in text</p>
</li>
<li><p>During decoding process, the previous output tag is used as the input to predict next tag. In this way, the network could capture tag correlation info.</p>
</li>
<li><p>Use a shared embedding layer to learn representation of text and tags in the same space. Besides, the author add an Indicator Function to explicitly  indicate the probability of directly copying a word from the content as the tag. The probability of copying a word is calculate as<br>$$<br>o_i = v_2^T. \tanh (W_3.s_i) \<br>p_i = \sigma(o_i)<br>$$<br>where $s_i$ is the overall content representation for predicting current tag. $v_2$ and $W_3$ are parameters.</p>
</li>
<li><p>Finally, the probability of a tag a is combination of probability of recommending a new tag and copying a word.<br>$$<br>P^{‘}(z_i) = (1-p_i)(p(z_i)) + p_i . \alpha(z_i)<br>$$<br>where $\alpha(z_i)$ is the attention weight of each word in the original text.</p>
</li>
</ol>
<h1 id="Hashtag-Recommendation-for-Photo-Sharing-Services"><a href="#Hashtag-Recommendation-for-Photo-Sharing-Services" class="headerlink" title="Hashtag Recommendation for Photo Sharing Services"></a>Hashtag Recommendation for Photo Sharing Services</h1><p>Problem: Hashtag recommendation for photo sharing services</p>
<p>Gap: In this scenario, each photo post has a text description and each user has some historical posts with tags. So previous methods failed to capture all of image info, text info and personalized user habits in an integral model.</p>
<p>Method:</p>
<p><img src="/img/aaai19/photo-tag-arch.PNG" alt=""></p>
<p>As shown in above figure, the general process is summarized as follows:</p>
<ol>
<li>Use a co-attention based Post Feature Extraction that considers the co-influence of image and text to extract Post Feature.</li>
<li>Use Post Feature $p$ as attention point to extract representation of related tags in a user’s historical post, denoted as Influence Vector $t$</li>
<li>Concatenate content feature $p$ and personal habit $t$ as the Overall Feature to give the final prediction.</li>
</ol>
<p>Again, A Nice Attention Introduction: <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a></p>
<h1 id="Holographic-Factorization-Machines-for-Recommendation"><a href="#Holographic-Factorization-Machines-for-Recommendation" class="headerlink" title="Holographic Factorization Machines for Recommendation"></a>Holographic Factorization Machines for Recommendation</h1><p>Problem: Recommendation basic methods</p>
<p>Gap: A new Holographic Factorization Machines based on FM utilizing the power of  Holographic Reduced Representation.</p>
<p>Method: In a simply word, the authors use circular convolution operator to replace the inner product operator in FM.</p>
<p>FM:</p>
<p><img src="/img/aaai19/hfm-fm.PNG" alt=""></p>
<p>HFM:</p>
<p><img src="/img/aaai19/hfm.PNG" alt=""></p>
<p>where $L(x) = w_0 + \sum_{i=1}^nw_ix_i$ and circular convolution operator(here $a$ and $b$ are both vectors other than matrix in CNN) is defined as</p>
<p><img src="/img/aaai19/hfm-convolution.PNG" alt=""></p>
<h1 id="Evaluating-Recommender-System-Stability-with-Influence-Guided-Fuzzing"><a href="#Evaluating-Recommender-System-Stability-with-Influence-Guided-Fuzzing" class="headerlink" title="Evaluating Recommender System Stability with Influence-Guided Fuzzing"></a>Evaluating Recommender System Stability with Influence-Guided Fuzzing</h1><p>Problem: Evaluate the stability of Recommender System</p>
<p>Gap: A new aspect. The idea is similar to adversary examples in CV, but the problem is proposed independently in the paper. The authors design a method (Influence-Guided Fuzzing) to find small sets of modifications (add, remove, change)  to train data that cause significantly instability of some recommendation methods.</p>
<p>Method: Influence-Guided Fuzzing</p>
<ol>
<li><p>Inferring Influence: The authors define four kinds of <em>influence</em> to measure the impact of <em>user</em>, <em>item</em>, <em>attribute</em> and <em>rating</em> on recommendations.</p>
</li>
<li><p>Based on the <em>influence</em> defined above, the author defines some modifications to the dataset shown in the following table.</p>
<p><img src="/img/aaai19/influence-fuzzing.PNG" alt=""></p>
</li>
<li><p>Finally, the authors apply these modifications to the dataset and test the result.</p>
</li>
</ol>
<p>This heuristics method defines a lot modifications which are not as elegant as the gradient-based adversary examples in CV.</p>
<h1 id="Joint-Representation-Learning-for-Multi-Modal-Transportation-Recommendation"><a href="#Joint-Representation-Learning-for-Multi-Modal-Transportation-Recommendation" class="headerlink" title="Joint Representation Learning for Multi-Modal Transportation Recommendation"></a>Joint Representation Learning for Multi-Modal Transportation Recommendation</h1><p>Problem: Multi-modal transportation recommendation</p>
<p>Gap: Most previous works focus on improving unimodal transport planning.</p>
<p>Challenges to do multi-modal transportation recommendation:</p>
<ol>
<li>transport heterogeneity</li>
<li>incomplete and implicit feedbacks</li>
<li>geo-spatial locality</li>
</ol>
<p>Method: </p>
<p><img src="/img/aaai19/trans-framework.PNG" alt=""></p>
<p>Firstly, a lot of work is to format data. As shown in the above figure, the authors build a MMTG (Multi-modal Transportation Graph) from all kinds of raw data. An example of MMTG is shown in the following figure.</p>
<p><img src="/img/aaai19/trans-mmtg.PNG" alt=""></p>
<p>Three kinds of nodes: Users, Transport modes, OD(Origin-Destination) pairs.</p>
<p>Four kinds of edges: user-user, user-mode, mode-od, od-od</p>
<p>Then the personalized recommendation task is formulated as:</p>
<ol>
<li><p>The data is a set of historical travel event, denote as $&lt;u,m,od&gt;$ where $u, m, od$ are user, mode and OD pair. Then given a new $&lt;u, od&gt;$, we want to recommend a most appropriate mode $m$.</p>
</li>
<li><p>Logistic loss with negative sampling</p>
<p><img src="/img/aaai19/trans-loss.PNG" alt=""></p>
</li>
</ol>
<p>The method is simple and the contribution is to format the complex problem. </p>
<h1 id="Hierarchical-Reinforcement-Learning-for-Course-Recommendation-in-MOOCs"><a href="#Hierarchical-Reinforcement-Learning-for-Course-Recommendation-in-MOOCs" class="headerlink" title="Hierarchical Reinforcement Learning for Course Recommendation in MOOCs"></a>Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</h1><p>Problem: Course Recommendation in MOOCs</p>
<p>Gap: For previous attention-based works, when a user has interests in many different courses, the attention mechanism will perform poorly as the effects of the contributing courses are diluted by diverse historical courses.  An example is shown in the following figure, for a trained attention-based model, the real target course get lower recommendation probability than a random selected course although it give more related courses more weights.</p>
<p><img src="/img/aaai19/course-intuition.PNG" alt=""></p>
<p>More analyses on dataset is shown in the following figure. From figure (b), we can the category ratio is evenly distributed for all users. From figure (c), we can see as the category ratio grows larger which means these users like more kinds of courses, a trained attention-based model give lower recommendation probability to the target courses.</p>
<p><img src="/img/aaai19/course-data.PNG" alt=""></p>
<p>Method: Use RL to revise user profiles by removing the noisy courses instead of assigning an attention weight to each of them.</p>
<p><img src="/img/aaai19/course-arch.PNG" alt=""></p>
<p>As shown in the above figure, the process is briefly summarized as:</p>
<ol>
<li>Use a two level Markov Decision Process(MDP) to decide how to revise the original profile. Firstly, a high level MDP to decide whether to revise the profile. Then if the high level MDP decides to revise the profile, a low level MDP will decide how to revise the profile. Finally the revised profile (maybe no change) will delivered to a basic recommendation model for training.</li>
<li>The reward R to decide how to revise current profile is the difference of recommendation probabilities using revised profile and original profile. The internal reward G is the difference of similarity between (revised profile, target course) and similarity between (original profile, target course)</li>
</ol>
<p>Other details is omitted here.</p>
<h1 id="Non-Compensatory-Psychological-Models-for-Recommender-Systems"><a href="#Non-Compensatory-Psychological-Models-for-Recommender-Systems" class="headerlink" title="Non-Compensatory Psychological Models for Recommender Systems"></a>Non-Compensatory Psychological Models for Recommender Systems</h1><p>Problem: Basic recommendation method</p>
<p>Gap: A novel aspect. The study of consumer psychology reveals two categories of consumption decision procedures: compensatory rules and non-compensatory rules. Under compensatory rules a consumer evaluates an item over all relevant aspects  and a good performance on one aspect of an item compensates for poor performances on other aspects. So all traditional latent factor based methods fall into the category of compensatory rules. However, in the study of human choice behavior, it is well regarded that consumers more frequently make consumption related choice based on non-compensatory rules which do not allow the shortcomings of a product be balanced out by its attractive features. So the authors propose a method based on non-compensatory rules.</p>
<p>Method:</p>
<p>Introduction of some non-compensatory rules:</p>
<ol>
<li>Lexicographic rule: this rules assumes that aspects of products can be ordered in terms of importance and alternative brands are evaluated sequentially from the most prominent to the least prominent aspects.</li>
<li>Conjunctive rule: This rule establishes a minimally acceptable the acceptable threshold for each aspect.</li>
</ol>
<p>Model framework:</p>
<p><img src="/img/aaai19/nc-framework.PNG" alt=""></p>
<p>As shown in above figure, the authors assume a user’s preference on all aspects consists of two parts: prominent aspect and non-prominent part. For evaluation on prominent aspect, the score should be maximized while for evaluation on non-prominent aspects, the scores just need to satisfy some thresholds.</p>
<p>Following this idea, the authors changes many traditional models like MF, AMF, Local Low-rank MF, BPR. Here we take MF for an example to illustrate the work.</p>
<p>For traditional MF, the predicted score $\hat{X}<em>{u,q}$ for user vector $u$ and item vector (v) is calculated as:<br>$$<br>\hat{X}</em>{u,q} = \sum_{k=1}^Kq_ku_k<br>$$<br>where $K$ is dimension of latent factors.</p>
<p>Then under non-prominent rules, preference $u$ represents the a distribution of whether each aspect is a prominent aspect or not. Then for MF, the author firstly sample a prominent aspect from u as:<br>$$<br>k \sim \frac{\exp u_k}{\sum_{k^{‘}}\exp u_{k^{‘}}}<br>$$<br>Then the prominent aspect is magnified by parameter $\exp \theta$ and the non-prominent aspect should satisfy a threshold $b_{u,k^{‘}}$. Finally, the overall evaluation score is calculated as:<br>$$<br>\hat{X}<em>{u,q} = \sum</em>{k=1}^K\frac{\exp u_K}{\sum_{k^{‘}}\exp u_{k^{‘}}}[q_k\exp\theta + \sum_{k^{‘} \neq k}(q_{k^{‘}} - b_{u,k^{‘}})]<br>$$</p>
<h1 id="Modeling-Influential-Contexts-with-Heterogeneous-Relations-for-Sparse-and-Cold-Start-Recommendation"><a href="#Modeling-Influential-Contexts-with-Heterogeneous-Relations-for-Sparse-and-Cold-Start-Recommendation" class="headerlink" title="Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation"></a>Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation</h1><p>Problem: Recommendation with influential contexts(social relation and item-item relation)</p>
<p>Gap: </p>
<p><img src="/img/aaai19/context-intuition.PNG" alt=""></p>
<p>As shown in above figure, the authors format a general recommendation with influential contexts(social relation and item-item relation) and user-item interaction. In this view, most previous works have only partially considered this problem with info of at most two relations.</p>
<p>Method:</p>
<p><img src="/img/aaai19/context-arch.PNG" alt=""></p>
<p>The general process is clearly shown in the above figure. The Representers $E$ is just latent embedding. The Aggregator of user has two level of modules based attention(capturing influence of friends’ friends). The Aggregator of item has only one level attention network. Finally, the User-item Interaction is inner product.</p>
<p>In this way, the final score contains influence of four parts as follows:</p>
<p><img src="/img/aaai19/context-score.PNG" alt=""></p>
<p>where in order the influence of four parts are: user - item, user - item context, user context - item, user context - item context.</p>
<h1 id="Large-scale-Interactive-Recommendation-with-Tree-structured-Policy-Gradient"><a href="#Large-scale-Interactive-Recommendation-with-Tree-structured-Policy-Gradient" class="headerlink" title="Large-scale Interactive Recommendation with Tree-structured Policy Gradient"></a>Large-scale Interactive Recommendation with Tree-structured Policy Gradient</h1><p>Problem: Interactive Recommendation (here the definition is more similar to online recommendation)</p>
<p>Gap: With a large number of items, traditional RL methods that handle the problem with linear time complexity is not efficient enough. </p>
<p>Method: Tree-structed Policy Gradient.</p>
<p><img src="/img/aaai19/irs-tree.PNG" alt=""></p>
<p>As shown in the above figure, the authors build a tree of items according to similarities of different items. Then the decision process of choosing a item is finding a path on the tree(about logN complexity) instead of finding one item from all items(N complexity)</p>
<p>Complexity of finding a path on the tree:</p>
<p>The depth of the tree is denoted as d, and each node has at most c children. Then the complexity of making  decision in each Policy Network is as most c. Then total complexity is d*c which is approximately equal to logN.</p>
<p>The performance of this method highly depend on the quality of the built tree. The authors use three ways to represent each item as an vector and then user clustering method to cluster all items level by level to build the tree.</p>
<ol>
<li>Raw rating vector.</li>
<li>latent factors of MF</li>
<li>Use VAE to encode raw rating vector.</li>
</ol>
<p>My concern is all these three ways are hard to learn a good representation with sparse ratings.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Recommender-Systems/" rel="tag"># Recommender Systems</a>
          
            <a href="/tags/Knowledge-graph/" rel="tag"># Knowledge graph</a>
          
            <a href="/tags/RNN/" rel="tag"># RNN</a>
          
            <a href="/tags/Attention-Mechanism/" rel="tag"># Attention Mechanism</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/05/14/Paper-Notes-About-Recommendation-in-SIGIR18/" rel="next" title="Paper_Notes_About_Recommendation_in_SIGIR18">
                <i class="fa fa-chevron-left"></i> Paper_Notes_About_Recommendation_in_SIGIR18
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/25/Session-Recommendation/" rel="prev" title="Session Recommendation">
                Session Recommendation <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.gif"
                alt="N4A" />
            
              <p class="site-author-name" itemprop="name">N4A</p>
              <p class="site-description motion-element" itemprop="description">To explore and understand</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/n4a" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://maliut.space/" title="Maliut Space" target="_blank">Maliut Space</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://ravensanstete.github.io/" title="Ravensanstete" target="_blank">Ravensanstete</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Explainability"><span class="nav-number">2.1.</span> <span class="nav-text">Explainability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sequential-Recommendation"><span class="nav-number">2.2.</span> <span class="nav-text">Sequential Recommendation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cross-Domain-Recommendation"><span class="nav-number">2.3.</span> <span class="nav-text">Cross Domain Recommendation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Improve-Basic-Methods"><span class="nav-number">2.4.</span> <span class="nav-text">Improve Basic Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Specific-Tasks"><span class="nav-number">2.5.</span> <span class="nav-text">Specific Tasks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Others"><span class="nav-number">2.6.</span> <span class="nav-text">Others</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Session-based-Recommendation-with-Graph-Neural-Networks"><span class="nav-number">3.</span> <span class="nav-text">Session-based Recommendation with Graph Neural Networks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Collaborative-Ranking-Method-for-Content-Based-Recommendation"><span class="nav-number">4.</span> <span class="nav-text">A Collaborative Ranking Method for Content Based Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Explainable-Reasoning-over-Knowledge-Graphs-for-Recommendation"><span class="nav-number">5.</span> <span class="nav-text">Explainable Reasoning over Knowledge Graphs for Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#From-Zero-Shot-Learning-to-Cold-Start-Recommendation"><span class="nav-number">6.</span> <span class="nav-text">From Zero-Shot Learning to Cold-Start Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Meta-Learning-for-Image-Captioning"><span class="nav-number">7.</span> <span class="nav-text">Meta Learning for Image Captioning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Explainable-Recommendation-Through-Attentive-Multi-View-Learning"><span class="nav-number">8.</span> <span class="nav-text">Explainable Recommendation Through Attentive Multi-View Learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dynamic-Explainable-Recommendation-based-on-Neural-Attentive-Models"><span class="nav-number">9.</span> <span class="nav-text">Dynamic Explainable Recommendation based on Neural Attentive Models</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DAN-Deep-Attention-Neural-Network-for-News-Recommendation"><span class="nav-number">10.</span> <span class="nav-text">DAN: Deep Attention Neural Network for News Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Repeat-Aware-Neural-Recommendation-Machine-for-Session-based-Recommendation"><span class="nav-number">11.</span> <span class="nav-text">A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hierarchical-Context-enabled-Recurrent-Neural-Network-for-Recommendation"><span class="nav-number">12.</span> <span class="nav-text">Hierarchical Context enabled Recurrent Neural Network for Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Spatio-Temporal-Gated-Network-for-Next-POI-Recommendation"><span class="nav-number">13.</span> <span class="nav-text">A Spatio-Temporal Gated Network for Next POI Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Multi-order-Attentive-Ranking-Model-for-Sequential-Recommendation"><span class="nav-number">14.</span> <span class="nav-text">Multi-order Attentive Ranking Model for Sequential Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Graph-Augmented-MEmory-Networks-for-Recommending-Medication-Combination"><span class="nav-number">15.</span> <span class="nav-text">Graph Augmented MEmory Networks for Recommending Medication Combination</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deeply-Fusing-Reviews-and-Contents-for-Cold-Start-Users-in-Cross-Domain-Recommendation-Systems"><span class="nav-number">16.</span> <span class="nav-text">Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Discrete-Social-Recommendation"><span class="nav-number">17.</span> <span class="nav-text">Discrete Social Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#A-Unified-Framework-of-Representation-Learning-and-Matching-Function-Learning-in-Recommender-System"><span class="nav-number">18.</span> <span class="nav-text">A Unified Framework of Representation Learning and Matching Function Learning in Recommender System</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#An-Integral-Tag-Recommendation-Model-for-Textual-Content"><span class="nav-number">19.</span> <span class="nav-text">An Integral Tag Recommendation Model for Textual Content</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hashtag-Recommendation-for-Photo-Sharing-Services"><span class="nav-number">20.</span> <span class="nav-text">Hashtag Recommendation for Photo Sharing Services</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Holographic-Factorization-Machines-for-Recommendation"><span class="nav-number">21.</span> <span class="nav-text">Holographic Factorization Machines for Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Evaluating-Recommender-System-Stability-with-Influence-Guided-Fuzzing"><span class="nav-number">22.</span> <span class="nav-text">Evaluating Recommender System Stability with Influence-Guided Fuzzing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Joint-Representation-Learning-for-Multi-Modal-Transportation-Recommendation"><span class="nav-number">23.</span> <span class="nav-text">Joint Representation Learning for Multi-Modal Transportation Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hierarchical-Reinforcement-Learning-for-Course-Recommendation-in-MOOCs"><span class="nav-number">24.</span> <span class="nav-text">Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Non-Compensatory-Psychological-Models-for-Recommender-Systems"><span class="nav-number">25.</span> <span class="nav-text">Non-Compensatory Psychological Models for Recommender Systems</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Modeling-Influential-Contexts-with-Heterogeneous-Relations-for-Sparse-and-Cold-Start-Recommendation"><span class="nav-number">26.</span> <span class="nav-text">Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Large-scale-Interactive-Recommendation-with-Tree-structured-Policy-Gradient"><span class="nav-number">27.</span> <span class="nav-text">Large-scale Interactive Recommendation with Tree-structured Policy Gradient</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">N4A</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: true,
        notify: true,
        appId: '1rqtaYkCCLXGS6RQtruMohER-gzGzoHsz',
        appKey: 'zzD19hKziE9WJaUsI3RN2RzB',
        placeholder: 'Just go go',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("1rqtaYkCCLXGS6RQtruMohER-gzGzoHsz", "zzD19hKziE9WJaUsI3RN2RzB");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "default";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "Center";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
